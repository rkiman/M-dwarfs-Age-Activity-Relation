{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import src\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load references for moving groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_ref = Table.read('data/moving_groups_ref.csv',format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ref = Table.read('data/source_ref.csv',format='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all,dec_all,spt_all = [],[],[]\n",
    "ewha_all,ewha_err_all = [],[]\n",
    "lhalbol_all,lhalbol_err_all = [],[]\n",
    "age_all,age_err_all = [],[]\n",
    "group_num_all,group_name_all = [],[]\n",
    "source_num_all,source_ref_all = [],[]\n",
    "rv_all,J_all,H_all,K_all = [],[],[],[]\n",
    "V_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alonso-Floriano 2015 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ansdell 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansdell2015 = fits.open('Catalogs/Sources/Ansdell2015.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_ansdell2015 = ansdell2015[1].data['_RA']     \n",
    "dec_ansdell2015 = ansdell2015[1].data['_DE']\n",
    "N_ansdell2015 = len(dec_ansdell2015)\n",
    "spt_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "ewha_ansdell2015 = ansdell2015[1].data['EWHa']\n",
    "ewha_err_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "lhalbol_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "lhalbol_err_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "age_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "age_err_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "#rv_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "\n",
    "group_num_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "group_name_ansdell2015 = np.ones(N_ansdell2015)*np.nan\n",
    "source_num_ansdell2015 = np.ones(N_ansdell2015)*source_ref['source_num'][source_ref['source_ref']=='Ansdell 2015'][0]\n",
    "source_ref_ansdell2015 = np.array(['Ansdell 2015' for x in range(N_ansdell2015)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_ansdell2015) \n",
    "dec_all.append(dec_ansdell2015)\n",
    "spt_all.append(spt_ansdell2015)\n",
    "ewha_all.append(ewha_ansdell2015)\n",
    "ewha_err_all.append(ewha_err_ansdell2015)\n",
    "lhalbol_all.append(lhalbol_ansdell2015)\n",
    "lhalbol_err_all.append(lhalbol_err_ansdell2015)\n",
    "age_all.append(age_ansdell2015)\n",
    "age_err_all.append(age_err_ansdell2015)\n",
    "#rv_all.append(rv_ansdell2015)\n",
    "group_num_all.append(group_num_ansdell2015)\n",
    "group_name_all.append(group_name_ansdell2015)\n",
    "source_num_all.append(source_num_ansdell2015)\n",
    "source_ref_all.append(source_ref_ansdell2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansdell2015.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayo 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayo2012 = Table.read('Catalogs/Sources/Bayo2012.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_bayo2012 = np.array(np.array(bayo2012['_RA']))\n",
    "dec_bayo2012 = np.array(np.array(bayo2012['_DE']))\n",
    "N_bayo2012 = len(dec_bayo2012)\n",
    "spt_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "ewha_bayo2012 = np.array(bayo2012['W_Ha_'])*(-1)\n",
    "ewha_err_bayo2012 = np.array(bayo2012['e_W_Ha_'])\n",
    "lhalbol_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "lhalbol_err_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "age_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "age_err_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "#rv_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "\n",
    "group_num_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "group_name_bayo2012 = np.ones(N_bayo2012)*np.nan\n",
    "source_num_bayo2012 = np.ones(N_bayo2012)*source_ref['source_num'][source_ref['source_ref']=='Bayo 2012'][0]\n",
    "source_ref_bayo2012 = np.array(['Bayo 2012' for x in range(N_bayo2012)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_bayo2012) \n",
    "dec_all.append(dec_bayo2012)\n",
    "spt_all.append(spt_bayo2012)\n",
    "ewha_all.append(ewha_bayo2012)\n",
    "ewha_err_all.append(ewha_err_bayo2012)\n",
    "lhalbol_all.append(lhalbol_bayo2012)\n",
    "lhalbol_err_all.append(lhalbol_err_bayo2012)\n",
    "age_all.append(age_bayo2012)\n",
    "age_err_all.append(age_err_bayo2012)\n",
    "#rv_all.append(rv_bayo2012)\n",
    "group_num_all.append(group_num_bayo2012)\n",
    "group_name_all.append(group_name_bayo2012)\n",
    "source_num_all.append(source_num_bayo2012)\n",
    "source_ref_all.append(source_ref_bayo2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bochanski 2005 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bouy 2009: Upper Sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bouy2009 = fits.open('Catalogs/Sources/Bouy2009.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_bouy2009,dec_bouy2009 = src.hstodeg(bouy2009[1].data['RAJ2000'],bouy2009[1].data['DEJ2000'])\n",
    "N_bouy2009 = len(dec_bouy2009)\n",
    "spt_bouy2009 = src.organize_spt(bouy2009[1].data['SpT'])\n",
    "ewha_bouy2009 = bouy2009[1].data['EWHa']*(-1)\n",
    "ewha_err_bouy2009 = np.ones(N_bouy2009)*0.1 #says in the paper\n",
    "lhalbol_bouy2009 = np.ones(N_bouy2009)*np.nan\n",
    "lhalbol_err_bouy2009 = np.ones(N_bouy2009)*np.nan\n",
    "kmag_bouy2009 = np.ones(N_bouy2009)*np.nan\n",
    "kmag_err_bouy2009 = np.ones(N_bouy2009)*np.nan\n",
    "age_bouy2009 = np.ones(N_bouy2009)*mg_ref['age'][mg_ref['name']=='USCO'][0]\n",
    "age_err_bouy2009 = np.ones(N_bouy2009)*mg_ref['age_error'][mg_ref['name']=='USCO'][0]\n",
    "\n",
    "group_num_bouy2009 = np.ones(N_bouy2009)*mg_ref['group_num'][mg_ref['name']=='USCO'][0]\n",
    "group_name_bouy2009 = np.array(['USCO' for i in range(N_bouy2009)])\n",
    "source_num_bouy2009 = np.ones(N_bouy2009)*source_ref['source_num'][source_ref['source_ref']=='Bouy 2009'][0]\n",
    "source_ref_bouy2009 = np.array(['Bouy 2009' for x in range(N_bouy2009)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bouy2009.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_bouy2009) \n",
    "dec_all.append(dec_bouy2009)\n",
    "spt_all.append(spt_bouy2009)\n",
    "ewha_all.append(ewha_bouy2009)\n",
    "ewha_err_all.append(ewha_err_bouy2009)\n",
    "lhalbol_all.append(lhalbol_bouy2009)\n",
    "lhalbol_err_all.append(lhalbol_err_bouy2009)\n",
    "age_all.append(age_bouy2009)\n",
    "age_err_all.append(age_err_bouy2009)\n",
    "group_num_all.append(group_num_bouy2009)\n",
    "group_name_all.append(group_name_bouy2009)\n",
    "source_num_all.append(source_num_bouy2009)\n",
    "source_ref_all.append(source_ref_bouy2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruz 2002 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Douglas 2014: Praesepe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "douglas2014_p = fits.open('Catalogs/Sources/Douglas2014_praesepe.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid keyword for column 7: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-2147483648'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "N_douglas2014_p = len(douglas2014_p[1].data['_RAJ2000'])\n",
    "ra_douglas2014_p = douglas2014_p[1].data['_RAJ2000']\n",
    "dec_douglas2014_p = douglas2014_p[1].data['_DEJ2000']\n",
    "spt_douglas2014_p = src.organize_spt(douglas2014_p[1].data['SpType'])\n",
    "ewha_douglas2014_p = douglas2014_p[1].data['EW']*-1\n",
    "ewha_err_douglas2014_p = douglas2014_p[1].data['e_EW']\n",
    "lhalbol_douglas2014_p = douglas2014_p[1].data['Lum']*1e-5\n",
    "lhalbol_err_douglas2014_p = douglas2014_p[1].data['e_Lum']*1e-5\n",
    "kmag_douglas2014_p = douglas2014_p[1].data['Kmag']\n",
    "kmag_err_douglas2014_p = douglas2014_p[1].data['e_Kmag']\n",
    "age_douglas2014_p = np.ones(N_douglas2014_p)*mg_ref['age'][mg_ref['name']=='PRA'][0]\n",
    "age_err_douglas2014_p = np.ones(N_douglas2014_p)*mg_ref['age_error'][mg_ref['name']=='PRA'][0]\n",
    "group_num_douglas2014_p = np.ones(N_douglas2014_p)*mg_ref['group_num'][mg_ref['name']=='PRA'][0]\n",
    "group_name_douglas2014_p = np.array(['PRA' for x in range(N_douglas2014_p)])\n",
    "source_num_douglas2014_p = np.ones(N_douglas2014_p)*source_ref['source_num'][source_ref['source_ref']=='Douglas 2014'][0]\n",
    "source_ref_douglas2014_p = np.array(['Douglas 2014' for x in range(N_douglas2014_p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [ewha_douglas2014_p,ewha_err_douglas2014_p,lhalbol_douglas2014_p,lhalbol_err_douglas2014_p]:\n",
    "    mask = column == 0.0\n",
    "    column[mask] = np.nan\n",
    "    mask = column == -0.0\n",
    "    column[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "douglas2014_p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_douglas2014_p) \n",
    "dec_all.append(dec_douglas2014_p)\n",
    "spt_all.append(spt_douglas2014_p)\n",
    "ewha_all.append(ewha_douglas2014_p)\n",
    "ewha_err_all.append(ewha_err_douglas2014_p)\n",
    "lhalbol_all.append(lhalbol_douglas2014_p)\n",
    "lhalbol_err_all.append(lhalbol_err_douglas2014_p)\n",
    "age_all.append(age_douglas2014_p)\n",
    "age_err_all.append(age_err_douglas2014_p)\n",
    "group_num_all.append(group_num_douglas2014_p)\n",
    "group_name_all.append(group_name_douglas2014_p)\n",
    "source_num_all.append(source_num_douglas2014_p)\n",
    "source_ref_all.append(source_ref_douglas2014_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Douglas 2014: Hyades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "douglas2014_h = fits.open('Catalogs/Sources/Douglas2014_hyades.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_douglas2014_h = len(douglas2014_h[1].data['_RAJ2000'])\n",
    "ra_douglas2014_h = douglas2014_h[1].data['_RAJ2000']\n",
    "dec_douglas2014_h = douglas2014_h[1].data['_DEJ2000']\n",
    "spt_douglas2014_h = src.organize_spt(douglas2014_h[1].data['SpTypeH'])\n",
    "ewha_douglas2014_h = douglas2014_h[1].data['EW']*-1\n",
    "ewha_err_douglas2014_h = douglas2014_h[1].data['e_EW']\n",
    "lhalbol_douglas2014_h = douglas2014_h[1].data['Lum']*1e-5\n",
    "lhalbol_err_douglas2014_h = douglas2014_h[1].data['e_Lum']*1e-5\n",
    "kmag_douglas2014_h = douglas2014_h[1].data['Kmag']\n",
    "kmag_err_douglas2014_h = douglas2014_h[1].data['e_Kmag']\n",
    "age_douglas2014_h = np.ones(N_douglas2014_h)*mg_ref['age'][mg_ref['name']=='HYA'][0]\n",
    "age_err_douglas2014_h = np.ones(N_douglas2014_h)*mg_ref['age_error'][mg_ref['name']=='HYA'][0]\n",
    "group_num_douglas2014_h = np.ones(N_douglas2014_h)*mg_ref['group_num'][mg_ref['name']=='HYA'][0]\n",
    "group_name_douglas2014_h = np.array(['HYA' for x in range(N_douglas2014_h)])\n",
    "source_num_douglas2014_h = np.ones(N_douglas2014_h)*source_ref['source_num'][source_ref['source_ref']=='Douglas 2014'][0]\n",
    "source_ref_douglas2014_h = np.array(['Douglas 2014' for x in range(N_douglas2014_h)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [ewha_douglas2014_h,ewha_err_douglas2014_h,lhalbol_douglas2014_h,lhalbol_err_douglas2014_h]:\n",
    "    mask = column == 0.0\n",
    "    column[mask] = np.nan\n",
    "    mask = column == -0.0\n",
    "    column[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "douglas2014_h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_douglas2014_h) \n",
    "dec_all.append(dec_douglas2014_h)\n",
    "spt_all.append(spt_douglas2014_h)\n",
    "ewha_all.append(ewha_douglas2014_h)\n",
    "ewha_err_all.append(ewha_err_douglas2014_h)\n",
    "lhalbol_all.append(lhalbol_douglas2014_h)\n",
    "lhalbol_err_all.append(lhalbol_err_douglas2014_h)\n",
    "age_all.append(age_douglas2014_h)\n",
    "age_err_all.append(age_err_douglas2014_h)\n",
    "group_num_all.append(group_num_douglas2014_h)\n",
    "group_name_all.append(group_name_douglas2014_h)\n",
    "source_num_all.append(source_num_douglas2014_h)\n",
    "source_ref_all.append(source_ref_douglas2014_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliott 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliott2016 = fits.open('Catalogs/Sources/elliott2016.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_elliott2016 = elliott2016[1].data['RAJ2000']\n",
    "dec_elliott2016 = elliott2016[1].data['DEJ2000']\n",
    "N_elliott2016 = len(dec_elliott2016)\n",
    "spt_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "ewha_elliott2016 = elliott2016[1].data['EWHa']\n",
    "ewha_err_elliott2016 = elliott2016[1].data['e_EWHa']\n",
    "lhalbol_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "lhalbol_err_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "\n",
    "age_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "age_err_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "group_num_elliott2016 = np.ones(N_elliott2016)*np.nan\n",
    "\n",
    "group_name_elliott2016 = []\n",
    "names = np.array(['BPMG','ABDMG','THA','COL','ARG','OCT','TWA','EPSC','CAR'])\n",
    "names2 = np.array(['BPC','ABD','THA','COL','ARG','OCT','TWA','ECH','CAR'])\n",
    "for x in elliott2016[1].data['Assoc']:\n",
    "    mask = x == names2\n",
    "    group_name_elliott2016.append(names[mask][0])\n",
    "\n",
    "group_name_elliott2016 = np.array(group_name_elliott2016)\n",
    "for x in ['BPMG','ABDMG','THA','COL','ARG','OCT','TWA','EPSC','CAR']:\n",
    "    mask1 = group_name_elliott2016 == x\n",
    "    n_mask = len(elliott2016[1].data['Assoc'][mask1])\n",
    "    age_elliott2016[mask1] = np.ones(n_mask)*mg_ref['age'][mg_ref['name']==x][0]\n",
    "    age_err_elliott2016[mask1] = np.ones(n_mask)*mg_ref['age_error'][mg_ref['name']==x][0]\n",
    "    group_num_elliott2016[mask1] = np.ones(n_mask)*mg_ref['group_num'][mg_ref['name']==x][0]\n",
    "\n",
    "source_num_elliott2016 = np.ones(N_elliott2016)*source_ref['source_num'][source_ref['source_ref']=='Elliott 2016'][0]\n",
    "source_ref_elliott2016 = np.array(['Elliott 2016' for x in range(N_elliott2016)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_elliott2016) \n",
    "dec_all.append(dec_elliott2016)\n",
    "spt_all.append(spt_elliott2016)\n",
    "ewha_all.append(ewha_elliott2016)\n",
    "ewha_err_all.append(ewha_err_elliott2016)\n",
    "lhalbol_all.append(lhalbol_elliott2016)\n",
    "lhalbol_err_all.append(lhalbol_err_elliott2016)\n",
    "age_all.append(age_elliott2016)\n",
    "age_err_all.append(age_err_elliott2016)\n",
    "group_num_all.append(group_num_elliott2016)\n",
    "group_name_all.append(group_name_elliott2016)\n",
    "source_num_all.append(source_num_elliott2016)\n",
    "source_ref_all.append(source_ref_elliott2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fang 2018: Pleiades, M34, Praesepe and Hyades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv('Catalogs/Sources/Fang2018Table_F1_online.dat', sep=\"\\s+\")\n",
    "file2 = pd.read_csv('Catalogs/Sources/Fang2018Table_F2_online.dat', sep=\"\\s+\")\n",
    "file3 = pd.read_csv('Catalogs/Sources/Fang2018Table_F3_online.dat', sep=\"\\s+\")\n",
    "file4 = pd.read_csv('Catalogs/Sources/Fang2018Table_F4_online.dat', sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(file1['EWHa']) + len(file2['EWHa']) + len(file3['EWHa']) + len(file4['EWHa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "teff1 = file1['#Teff']\n",
    "ewha1 = file1['EWHa']\n",
    "multi1 = file1['multi'] == 0\n",
    "N1 = len(file1['EWHa'])\n",
    "group1 = np.array(['PLE' for x in range(N1)])\n",
    "group_num1 = np.ones(N1)*mg_ref['group_num'][mg_ref['name']=='PLE'][0]\n",
    "age1 = np.ones(N1)*mg_ref['age'][mg_ref['name']=='PLE'][0]\n",
    "age_err1 = np.ones(N1)*mg_ref['age_error'][mg_ref['name']=='PLE'][0]\n",
    "ra1 = file1['RAJ2000']\n",
    "dec1 = file1['DEJ2000']\n",
    "\n",
    "teff2 = file2['Teff']\n",
    "ewha2 = file2['EWHa']\n",
    "N2 = len(file2['EWHa'])\n",
    "multi2 = np.array([True for x in range(N2)])\n",
    "group2 = np.array(['M34' for x in range(N2)])\n",
    "group_num2 = np.ones(N2)*mg_ref['group_num'][mg_ref['name']=='M34'][0]\n",
    "age2 = np.ones(N2)*mg_ref['age'][mg_ref['name']=='M34'][0]\n",
    "age_err2 = np.ones(N2)*mg_ref['age_error'][mg_ref['name']=='M34'][0]\n",
    "ra2 = file2['RAJ2000']\n",
    "dec2 = file2['DEJ2000']\n",
    "\n",
    "teff3 = file3['Teff']\n",
    "ewha3 = file3['EWHa']\n",
    "N3 = len(file3['EWHa'])\n",
    "multi3 = np.array([True for x in range(N3)])\n",
    "group3 = np.array(['PRA' for x in range(N3)])\n",
    "group_num3 = np.ones(N3)*mg_ref['group_num'][mg_ref['name']=='PRA'][0]\n",
    "age3 = np.ones(N3)*mg_ref['age'][mg_ref['name']=='PRA'][0]\n",
    "age_err3 = np.ones(N3)*mg_ref['age_error'][mg_ref['name']=='PRA'][0]\n",
    "ra3 = file3['RAJ2000']\n",
    "dec3 = file3['DEJ2000']\n",
    "\n",
    "teff4 = file4['Teff']\n",
    "ewha4 = file4['EWHa']\n",
    "multi4 = file4['multi'] == 0\n",
    "N4 = len(file4['EWHa'])\n",
    "group4 = np.array(['HYA' for x in range(N4)])\n",
    "group_num4 = np.ones(N4)*mg_ref['group_num'][mg_ref['name']=='HYA'][0]\n",
    "age4 = np.ones(N4)*mg_ref['age'][mg_ref['name']=='HYA'][0]\n",
    "age_err4 = np.ones(N4)*mg_ref['age_error'][mg_ref['name']=='HYA'][0]\n",
    "ra4 = file4['RAJ2000']\n",
    "dec4 = file4['DEJ2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_fang2018 = np.concatenate((ra1[multi1],ra2[multi2],ra3[multi3],ra4[multi4]))\n",
    "dec_fang2018 = np.concatenate((dec1[multi1],dec2[multi2],dec3[multi3],dec4[multi4]))\n",
    "N_fang2018 = len(dec_fang2018)\n",
    "spt_fang2018 = np.nan*np.ones(N_fang2018)\n",
    "ewha_fang2018 = np.concatenate((ewha1[multi1],ewha2[multi2],ewha3[multi3],ewha4[multi4]))\n",
    "ewha_err_fang2018 = 0.5*np.ones(N_fang2018)\n",
    "lhalbol_fang2018 = np.nan*np.ones(N_fang2018)\n",
    "lhalbol_err_fang2018 = np.nan*np.ones(N_fang2018)\n",
    "kmag_fang2018 = np.nan*np.ones(N_fang2018)\n",
    "kmag_err_fang2018 = np.nan*np.ones(N_fang2018)\n",
    "age_fang2018 = np.concatenate((age1[multi1],age2[multi2],age3[multi3],age4[multi4]))\n",
    "age_err_fang2018 = np.concatenate((age_err1[multi1],age_err2[multi2],age_err3[multi3],age_err4[multi4]))\n",
    "group_num_fang2018 = np.concatenate((group_num1[multi1],group_num2[multi2],group_num3[multi3],group_num4[multi4]))\n",
    "group_name_fang2018 = np.concatenate((group1[multi1],group2[multi2],group3[multi3],group4[multi4]))\n",
    "source_num_fang2018 = np.ones(N_fang2018)*source_ref['source_num'][source_ref['source_ref']=='Fang 2018'][0]\n",
    "source_ref_fang2018 = np.array(['Fang 2018' for x in range(N_fang2018)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [ewha_fang2018]:\n",
    "    mask = column == -9999.0\n",
    "    column[mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_fang2018) \n",
    "dec_all.append(dec_fang2018)\n",
    "spt_all.append(spt_fang2018)\n",
    "ewha_all.append(ewha_fang2018)\n",
    "ewha_err_all.append(ewha_err_fang2018)\n",
    "lhalbol_all.append(lhalbol_fang2018)\n",
    "lhalbol_err_all.append(lhalbol_err_fang2018)\n",
    "age_all.append(age_fang2018)\n",
    "age_err_all.append(age_err_fang2018)\n",
    "group_num_all.append(group_num_fang2018)\n",
    "group_name_all.append(group_name_fang2018)\n",
    "source_num_all.append(source_num_fang2018)\n",
    "source_ref_all.append(source_ref_fang2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feigelson 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feigelson2003 = Table.read('Catalogs/Sources/Feigelson2003.csv', format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feigelson2003 = feigelson2003[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_feigelson2003,dec_feigelson2003 = [],[]\n",
    "for x,y in zip(np.array(feigelson2003['Ra']),np.array(feigelson2003['De'])):\n",
    "    radec = str(x)+' '+str(y)\n",
    "    coord = SkyCoord(radec, unit=(u.hourangle, u.deg))\n",
    "    ra_feigelson2003.append(coord.ra.deg)\n",
    "    dec_feigelson2003.append(coord.dec.deg)\n",
    "ra_feigelson2003 = np.array(ra_feigelson2003)\n",
    "dec_feigelson2003 = np.array(dec_feigelson2003)\n",
    "N_feigelson2003 = len(dec_feigelson2003)\n",
    "spt_feigelson2003 = np.array(feigelson2003['SpT'])\n",
    "ewha_feigelson2003 = np.array(feigelson2003['HAEW'])*(-1)\n",
    "ewha_err_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "lhalbol_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "lhalbol_err_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "\n",
    "age_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "age_err_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "group_num_feigelson2003 = np.ones(N_feigelson2003)*np.nan\n",
    "\n",
    "for x in ['BPMG','EPSC','THA','TWA']:\n",
    "    mask1 = feigelson2003['Group'] == x\n",
    "    age_feigelson2003[mask1] = np.ones(len(feigelson2003['Group'][mask1]))*mg_ref['age'][mg_ref['name']==x][0]\n",
    "    age_err_feigelson2003[mask1] = np.ones(len(feigelson2003['Group'][mask1]))*mg_ref['age_error'][mg_ref['name']==x][0]\n",
    "    group_num_feigelson2003[mask1] = np.ones(len(feigelson2003['Group'][mask1]))*mg_ref['group_num'][mg_ref['name']==x][0]\n",
    "    \n",
    "group_name_feigelson2003 = np.array(feigelson2003['Group'])\n",
    "source_num_feigelson2003 = np.ones(N_feigelson2003)*source_ref['source_num'][source_ref['source_ref']=='Feigelson 2003'][0]\n",
    "source_ref_feigelson2003 = np.array(['Feigelson 2003' for x in range(N_feigelson2003)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_feigelson2003) \n",
    "dec_all.append(dec_feigelson2003)\n",
    "spt_all.append(spt_feigelson2003)\n",
    "ewha_all.append(ewha_feigelson2003)\n",
    "ewha_err_all.append(ewha_err_feigelson2003)\n",
    "lhalbol_all.append(lhalbol_feigelson2003)\n",
    "lhalbol_err_all.append(lhalbol_err_feigelson2003)\n",
    "age_all.append(age_feigelson2003)\n",
    "age_err_all.append(age_err_feigelson2003)\n",
    "group_num_all.append(group_num_feigelson2003)\n",
    "group_name_all.append(group_name_feigelson2003)\n",
    "source_num_all.append(source_num_feigelson2003)\n",
    "source_ref_all.append(source_ref_feigelson2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frasca 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "frasca2018 = Table.read('Catalogs/Sources/Frasca2018.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_frasca2018 = np.array(np.array(frasca2018['RAJ2000']))\n",
    "dec_frasca2018 = np.array(np.array(frasca2018['DEJ2000']))\n",
    "N_frasca2018 = len(dec_frasca2018)\n",
    "spt_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "ewha_frasca2018 = np.array(frasca2018['EWHa'])*(-0.001)\n",
    "ewha_err_frasca2018 = np.array(frasca2018['e_EWHa'])*(0.001)\n",
    "lhalbol_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "lhalbol_err_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "age_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "age_err_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "\n",
    "group_num_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "group_name_frasca2018 = np.ones(N_frasca2018)*np.nan\n",
    "source_num_frasca2018 = np.ones(N_frasca2018)*source_ref['source_num'][source_ref['source_ref']=='Frasca 2018'][0]\n",
    "source_ref_frasca2018 = np.array(['Frasca 2018' for x in range(N_frasca2018)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_frasca2018) \n",
    "dec_all.append(dec_frasca2018)\n",
    "spt_all.append(spt_frasca2018)\n",
    "ewha_all.append(ewha_frasca2018)\n",
    "ewha_err_all.append(ewha_err_frasca2018)\n",
    "lhalbol_all.append(lhalbol_frasca2018)\n",
    "lhalbol_err_all.append(lhalbol_err_frasca2018)\n",
    "age_all.append(age_frasca2018)\n",
    "age_err_all.append(age_err_frasca2018)\n",
    "group_num_all.append(group_num_frasca2018)\n",
    "group_name_all.append(group_name_frasca2018)\n",
    "source_num_all.append(source_num_frasca2018)\n",
    "source_ref_all.append(source_ref_frasca2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaidos 2014 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gizis 1997 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gizis 2000 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gizis 2002 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hawley 1996 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivanov 2015 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jayawardhana 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jayawardhana2006 = Table.read('Catalogs/Sources/jayawardhana2006.csv', format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_jayawardhana2006 = np.array(jayawardhana2006['Ra'])     \n",
    "dec_jayawardhana2006 = np.array(jayawardhana2006['De'])\n",
    "N_jayawardhana2006 = len(dec_jayawardhana2006)\n",
    "spt_jayawardhana2006 = np.array(jayawardhana2006['SpT'])\n",
    "ewha_jayawardhana2006 = np.array(jayawardhana2006['EWHA'])*(-1)\n",
    "ewha_err_jayawardhana2006 = np.array(jayawardhana2006['EWHA_err'])\n",
    "lhalbol_jayawardhana2006 = np.ones(N_jayawardhana2006)*np.nan\n",
    "lhalbol_err_jayawardhana2006 = np.ones(N_jayawardhana2006)*np.nan\n",
    "\n",
    "age_jayawardhana2006 = np.ones(N_jayawardhana2006)*np.nan\n",
    "age_err_jayawardhana2006 = np.ones(N_jayawardhana2006)*np.nan\n",
    "group_num_jayawardhana2006 = np.ones(N_jayawardhana2006)*np.nan\n",
    "\n",
    "for x in ['BPMG','ETAC','THA','TWA']:\n",
    "    mask1 = jayawardhana2006['Group'] == x\n",
    "    age_jayawardhana2006[mask1] = np.ones(len(jayawardhana2006['Group'][mask1]))*mg_ref['age'][mg_ref['name']==x][0]\n",
    "    age_err_jayawardhana2006[mask1] = np.ones(len(jayawardhana2006['Group'][mask1]))*mg_ref['age_error'][mg_ref['name']==x][0]\n",
    "    group_num_jayawardhana2006[mask1] = np.ones(len(jayawardhana2006['Group'][mask1]))*mg_ref['group_num'][mg_ref['name']==x][0]\n",
    "    \n",
    "group_name_jayawardhana2006 = np.array(jayawardhana2006['Group'])\n",
    "source_num_jayawardhana2006 = np.ones(N_jayawardhana2006)*source_ref['source_num'][source_ref['source_ref']=='Jayawardhana 2006'][0]\n",
    "source_ref_jayawardhana2006 = np.array(['Jayawardhana 2006' for x in range(N_jayawardhana2006)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_jayawardhana2006) \n",
    "dec_all.append(dec_jayawardhana2006)\n",
    "spt_all.append(spt_jayawardhana2006)\n",
    "ewha_all.append(ewha_jayawardhana2006)\n",
    "ewha_err_all.append(ewha_err_jayawardhana2006)\n",
    "lhalbol_all.append(lhalbol_jayawardhana2006)\n",
    "lhalbol_err_all.append(lhalbol_err_jayawardhana2006)\n",
    "age_all.append(age_jayawardhana2006)\n",
    "age_err_all.append(age_err_jayawardhana2006)\n",
    "group_num_all.append(group_num_jayawardhana2006)\n",
    "group_name_all.append(group_name_jayawardhana2006)\n",
    "source_num_all.append(source_num_jayawardhana2006)\n",
    "source_ref_all.append(source_ref_jayawardhana2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeffers 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeffers2018 = fits.open('Catalogs/Sources/Jeffers2018.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_jeffers2018 = jeffers2018[1].data['_RA']     \n",
    "dec_jeffers2018 = jeffers2018[1].data['_DE']\n",
    "N_jeffers2018 = len(dec_jeffers2018)\n",
    "spt_jeffers2018 = jeffers2018[1].data['SpType']\n",
    "ewha_jeffers2018 = jeffers2018[1].data['pEWHa']*(-1)\n",
    "ewha_err_jeffers2018 = jeffers2018[1].data['e_pEWHa']\n",
    "lhalbol_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "lhalbol_err_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "age_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "age_err_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "\n",
    "group_num_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "group_name_jeffers2018 = np.ones(N_jeffers2018)*np.nan\n",
    "source_num_jeffers2018 = np.ones(N_jeffers2018)*source_ref['source_num'][source_ref['source_ref']=='Jeffers 2018'][0]\n",
    "source_ref_jeffers2018 = np.array(['Jeffers 2018' for x in range(N_jeffers2018)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_jeffers2018) \n",
    "dec_all.append(dec_jeffers2018)\n",
    "spt_all.append(spt_jeffers2018)\n",
    "ewha_all.append(ewha_jeffers2018)\n",
    "ewha_err_all.append(ewha_err_jeffers2018)\n",
    "lhalbol_all.append(lhalbol_jeffers2018)\n",
    "lhalbol_err_all.append(lhalbol_err_jeffers2018)\n",
    "age_all.append(age_jeffers2018)\n",
    "age_err_all.append(age_err_jeffers2018)\n",
    "group_num_all.append(group_num_jeffers2018)\n",
    "group_name_all.append(group_name_jeffers2018)\n",
    "source_num_all.append(source_num_jeffers2018)\n",
    "source_ref_all.append(source_ref_jeffers2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeffers2018.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiman 2019: MLSDSS-GaiaDR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_url = 'https://zenodo.org/record/2636692/files/MLSDSS-GaiaDR2_extended.fits?download=1'\n",
    "#kiman2019 = Table.read(target_url)\n",
    "kiman2019 = Table.read('/Users/rociokiman/Documents/Gaia-Cupid/Catalogs/MLSDSS-GaiaDR2.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdm_mask = kiman2019['WDM'] == 0 #Remove m dwarfs identified asmixed with a white dwarf.\n",
    "\n",
    "ra_kiman2019 = np.array(kiman2019['RA_SDSS'][wdm_mask])     \n",
    "dec_kiman2019 = np.array(kiman2019['DEC_SDSS'][wdm_mask])\n",
    "N_kiman2019 = len(dec_kiman2019)\n",
    "spt_kiman2019 = np.array(kiman2019['SPT'][wdm_mask])\n",
    "ewha_kiman2019 = np.array(kiman2019['EWHA'][wdm_mask])\n",
    "ewha_err_kiman2019 = np.array(kiman2019['EWHA_ERR'][wdm_mask])\n",
    "lhalbol_kiman2019 = np.array(kiman2019['LHALBOL'][wdm_mask])\n",
    "lhalbol_err_kiman2019 = np.array(kiman2019['LHALBOL_ERR'][wdm_mask])\n",
    "age_kiman2019 = np.ones(N_kiman2019)*np.nan\n",
    "age_err_kiman2019 = np.ones(N_kiman2019)*np.nan\n",
    "\n",
    "group_num_kiman2019 = np.ones(N_kiman2019)*np.nan\n",
    "group_name_kiman2019 = np.ones(N_kiman2019)*np.nan\n",
    "source_num_kiman2019 = np.ones(N_kiman2019)*source_ref['source_num'][source_ref['source_ref']=='Kiman 2019'][0]\n",
    "source_ref_kiman2019 = np.array(['Kiman 2019' for x in range(N_kiman2019)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_kiman2019) \n",
    "dec_all.append(dec_kiman2019)\n",
    "spt_all.append(spt_kiman2019)\n",
    "ewha_all.append(ewha_kiman2019)\n",
    "ewha_err_all.append(ewha_err_kiman2019)\n",
    "lhalbol_all.append(lhalbol_kiman2019)\n",
    "lhalbol_err_all.append(lhalbol_err_kiman2019)\n",
    "age_all.append(age_kiman2019)\n",
    "age_err_all.append(age_err_kiman2019)\n",
    "group_num_all.append(group_num_kiman2019)\n",
    "group_name_all.append(group_name_kiman2019)\n",
    "source_num_all.append(source_num_kiman2019)\n",
    "source_ref_all.append(source_ref_kiman2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kraus 2014: Tucana-Horologium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kraus2014 = fits.open('Catalogs/Sources/Kraus2014.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid keyword for column 21: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 22: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 38: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 39: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "ra_kraus2014 = kraus2014[1].data['_RAJ2000']\n",
    "dec_kraus2014 = kraus2014[1].data['_DEJ2000']\n",
    "N_kraus2014 = len(dec_kraus2014)\n",
    "spt_kraus2014 = src.organize_spt(kraus2014[1].data['SpT'])\n",
    "ewha_kraus2014 = kraus2014[1].data['EWHa']*(-1)\n",
    "ewha_err_kraus2014 = np.ones(N_kraus2014)*0.1 #says in the paper\n",
    "lhalbol_kraus2014 = np.ones(N_kraus2014)*np.nan\n",
    "lhalbol_err_kraus2014 = np.ones(N_kraus2014)*np.nan\n",
    "kmag_kraus2014 = np.ones(N_kraus2014)*np.nan\n",
    "kmag_err_kraus2014 = np.ones(N_kraus2014)*np.nan\n",
    "age_kraus2014 = np.ones(N_kraus2014)*mg_ref['age'][mg_ref['name']=='THA'][0]\n",
    "age_err_kraus2014 = np.ones(N_kraus2014)*mg_ref['age_error'][mg_ref['name']=='THA'][0]\n",
    "\n",
    "group_num_kraus2014 = np.ones(N_kraus2014)*mg_ref['group_num'][mg_ref['name']=='THA'][0]\n",
    "group_name_kraus2014 = np.array(['THA' for i in range(N_kraus2014)])\n",
    "source_num_kraus2014 = np.ones(N_kraus2014)*source_ref['source_num'][source_ref['source_ref']=='Kraus 2014'][0]\n",
    "source_ref_kraus2014 = np.array(['Kraus 2014' for x in range(N_kraus2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kraus2014.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_kraus2014) \n",
    "dec_all.append(dec_kraus2014)\n",
    "spt_all.append(spt_kraus2014)\n",
    "ewha_all.append(ewha_kraus2014)\n",
    "ewha_err_all.append(ewha_err_kraus2014)\n",
    "lhalbol_all.append(lhalbol_kraus2014)\n",
    "lhalbol_err_all.append(lhalbol_err_kraus2014)\n",
    "age_all.append(age_kraus2014)\n",
    "age_err_all.append(age_err_kraus2014)\n",
    "group_num_all.append(group_num_kraus2014)\n",
    "group_name_all.append(group_name_kraus2014)\n",
    "source_num_all.append(source_num_kraus2014)\n",
    "source_ref_all.append(source_ref_kraus2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lawson 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lawson2004 = np.array([129.1695833,129.4641667,130.3775000,130.8266667,132.1454167,132.8466667])     \n",
    "dec_lawson2004 = np.array([-78.9161111,-78.7436111,-78.8852778,-79.0891667,-78.8977778,-79.0897222])\n",
    "N_lawson2004 = len(dec_lawson2004)\n",
    "spt_lawson2004 = np.array([2,-5,4,2,5,-6])\n",
    "ewha_lawson2004 = np.array([0.9,1.1,-12,-110,-3.5,1.0])*(-1)\n",
    "ewha_err_lawson2004 = np.ones(N_lawson2004)*np.nan\n",
    "lhalbol_lawson2004 = np.ones(N_lawson2004)*np.nan\n",
    "lhalbol_err_lawson2004 = np.ones(N_lawson2004)*np.nan\n",
    "age_lawson2004 = np.ones(N_lawson2004)*mg_ref['age'][mg_ref['name']=='ETAC'][0]\n",
    "age_err_lawson2004 = np.ones(N_lawson2004)*mg_ref['age_error'][mg_ref['name']=='ETAC'][0]\n",
    "\n",
    "group_num_lawson2004 = np.ones(N_lawson2004)*mg_ref['group_num'][mg_ref['name']=='ETAC'][0]\n",
    "group_name_lawson2004 = np.array(['ETAC' for i in range(N_lawson2004)])\n",
    "source_num_lawson2004 = np.ones(N_lawson2004)*source_ref['source_num'][source_ref['source_ref']=='Lawson 2002'][0]\n",
    "source_ref_lawson2004 = np.array(['Lawson 2004' for x in range(N_lawson2004)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_lawson2004) \n",
    "dec_all.append(dec_lawson2004)\n",
    "spt_all.append(spt_lawson2004)\n",
    "ewha_all.append(ewha_lawson2004)\n",
    "ewha_err_all.append(ewha_err_lawson2004)\n",
    "lhalbol_all.append(lhalbol_lawson2004)\n",
    "lhalbol_err_all.append(lhalbol_err_lawson2004)\n",
    "age_all.append(age_lawson2004)\n",
    "age_err_all.append(age_err_lawson2004)\n",
    "group_num_all.append(group_num_lawson2004)\n",
    "group_name_all.append(group_name_lawson2004)\n",
    "source_num_all.append(source_num_lawson2004)\n",
    "source_ref_all.append(source_ref_lawson2004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lepine 2003 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lepine 2009 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lepine 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid keyword for column 31: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 47: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "lepine2013 = Table.read('Catalogs/Sources/Lepine2013.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lepine2013 = np.array(np.array(lepine2013['_RAJ2000']))\n",
    "dec_lepine2013 = np.array(np.array(lepine2013['_DEJ2000']))\n",
    "N_lepine2013 = len(dec_lepine2013)\n",
    "spt_lepine2013 = src.organize_spt(np.array([str(x) for x in lepine2013['SpT']]))\n",
    "ewha_lepine2013 = np.array(lepine2013['EWHa'])*(-1)\n",
    "ewha_err_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "lhalbol_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "lhalbol_err_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "age_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "age_err_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "\n",
    "group_num_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "group_name_lepine2013 = np.ones(N_lepine2013)*np.nan\n",
    "source_num_lepine2013 = np.ones(N_lepine2013)*source_ref['source_num'][source_ref['source_ref']=='Lepine 2013'][0]\n",
    "source_ref_lepine2013 = np.array(['Lepine 2013' for x in range(N_lepine2013)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_lepine2013) \n",
    "dec_all.append(dec_lepine2013)\n",
    "spt_all.append(spt_lepine2013)\n",
    "ewha_all.append(ewha_lepine2013)\n",
    "ewha_err_all.append(ewha_err_lepine2013)\n",
    "lhalbol_all.append(lhalbol_lepine2013)\n",
    "lhalbol_err_all.append(lhalbol_err_lepine2013)\n",
    "age_all.append(age_lepine2013)\n",
    "age_err_all.append(age_err_lepine2013)\n",
    "group_num_all.append(group_num_lepine2013)\n",
    "group_name_all.append(group_name_lepine2013)\n",
    "source_num_all.append(source_num_lepine2013)\n",
    "source_ref_all.append(source_ref_lepine2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LG11_obs (Andrew Mann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg11 = Table.read('Catalogs/Sources/LG11_obs.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lg11 = np.array(np.array(lg11['RA']))\n",
    "dec_lg11 = np.array(np.array(lg11['Dec']))\n",
    "N_lg11 = len(dec_lg11)\n",
    "spt_lg11 = src.organize_spt(np.array(lg11['SpT']))\n",
    "ewha_lg11 = np.array(lg11['EW_HA'])\n",
    "ewha_err_lg11 = np.ones(N_lg11)*0.5\n",
    "lhalbol_lg11 = np.ones(N_lg11)*np.nan\n",
    "lhalbol_err_lg11 = np.ones(N_lg11)*np.nan\n",
    "age_lg11 = np.ones(N_lg11)*np.nan\n",
    "age_err_lg11 = np.ones(N_lg11)*np.nan\n",
    "\n",
    "group_num_lg11 = np.ones(N_lg11)*np.nan\n",
    "group_name_lg11 = np.ones(N_lg11)*np.nan\n",
    "source_num_lg11 = np.ones(N_lg11)*source_ref['source_num'][source_ref['source_ref']=='LG11'][0]\n",
    "source_ref_lg11 = np.array(['LG11' for x in range(N_lg11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_lg11) \n",
    "dec_all.append(dec_lg11)\n",
    "spt_all.append(spt_lg11)\n",
    "ewha_all.append(ewha_lg11)\n",
    "ewha_err_all.append(ewha_err_lg11)\n",
    "lhalbol_all.append(lhalbol_lg11)\n",
    "lhalbol_err_all.append(lhalbol_err_lg11)\n",
    "age_all.append(age_lg11)\n",
    "age_err_all.append(age_err_lg11)\n",
    "group_num_all.append(group_num_lg11)\n",
    "group_name_all.append(group_name_lg11)\n",
    "source_num_all.append(source_num_lg11)\n",
    "source_ref_all.append(source_ref_lg11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lodieu 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lodieu2005_1 = Table.read('Catalogs/Sources/Lodieu2005_1.fit')\n",
    "lodieu2005_2 = Table.read('Catalogs/Sources/Lodieu2005_2.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lodieu2005 = []\n",
    "dec_lodieu2005 = []\n",
    "i=0\n",
    "for x in lodieu2005_1['Name']:\n",
    "    for y,ra_i,dec_i in zip(lodieu2005_2['Name'],lodieu2005_2['RAJ2000'],lodieu2005_2['DEJ2000']):\n",
    "        if(y.replace(\" \", \"\") in x.replace(\" \", \"\")):\n",
    "            ra_lodieu2005.append(ra_i)\n",
    "            dec_lodieu2005.append(dec_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lodieu2005 = np.array(ra_lodieu2005)\n",
    "dec_lodieu2005 = np.array(dec_lodieu2005)\n",
    "N_lodieu2005 = len(dec_lodieu2005)\n",
    "spt_lodieu2005 = src.organize_spt(np.array([str(x) for x in lodieu2005_1['SpType']]))\n",
    "ewha_lodieu2005 = np.array(lodieu2005_1['EWHa'])\n",
    "ewha_err_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "lhalbol_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "lhalbol_err_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "age_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "age_err_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "\n",
    "group_num_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "group_name_lodieu2005 = np.ones(N_lodieu2005)*np.nan\n",
    "source_num_lodieu2005 = np.ones(N_lodieu2005)*source_ref['source_num'][source_ref['source_ref']=='Lodieu 2005'][0]\n",
    "source_ref_lodieu2005 = np.array(['Lodieu 2005' for x in range(N_lodieu2005)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyo 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_lyo2004 = np.array([129.0441667,129.7145833])     \n",
    "dec_lyo2004 = np.array([-79.1383333,-79.2705556])\n",
    "N_lyo2004 = len(dec_lyo2004)\n",
    "spt_lyo2004 = np.array([5.5,5.2])\n",
    "ewha_lyo2004 = np.array([-8.3,-8.0])*(-1)\n",
    "ewha_err_lyo2004 = np.ones(N_lyo2004)*np.nan\n",
    "lhalbol_lyo2004 = np.ones(N_lyo2004)*np.nan\n",
    "lhalbol_err_lyo2004 = np.ones(N_lyo2004)*np.nan\n",
    "age_lyo2004 = np.ones(N_lyo2004)*mg_ref['age'][mg_ref['name']=='ETAC'][0]\n",
    "age_err_lyo2004 = np.ones(N_lyo2004)*mg_ref['age_error'][mg_ref['name']=='ETAC'][0]\n",
    "\n",
    "group_num_lyo2004 = np.ones(N_lyo2004)*mg_ref['group_num'][mg_ref['name']=='ETAC'][0]\n",
    "group_name_lyo2004 = np.array(['ETAC' for i in range(N_lyo2004)])\n",
    "source_num_lyo2004 = np.ones(N_lyo2004)*source_ref['source_num'][source_ref['source_ref']=='Lyo 2004'][0]\n",
    "source_ref_lyo2004 = np.array(['Lyo 2004' for x in range(N_lyo2004)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_lyo2004) \n",
    "dec_all.append(dec_lyo2004)\n",
    "spt_all.append(spt_lyo2004)\n",
    "ewha_all.append(ewha_lyo2004)\n",
    "ewha_err_all.append(ewha_err_lyo2004)\n",
    "lhalbol_all.append(lhalbol_lyo2004)\n",
    "lhalbol_err_all.append(lhalbol_err_lyo2004)\n",
    "age_all.append(age_lyo2004)\n",
    "age_err_all.append(age_err_lyo2004)\n",
    "group_num_all.append(group_num_lyo2004)\n",
    "group_name_all.append(group_name_lyo2004)\n",
    "source_num_all.append(source_num_lyo2004)\n",
    "source_ref_all.append(source_ref_lyo2004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malo 2014: BPMG, TWA, THA, COL, CAR, ARG, ABDMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "malo2014 = fits.open('Catalogs/Sources/Malo2014.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpic3 = malo2014[1].data['bPicP3']\n",
    "twhya3 = malo2014[1].data['TWAP3']\n",
    "tuchor3 = malo2014[1].data['THAP3']\n",
    "columb3 = malo2014[1].data['ColP3']\n",
    "car3 = malo2014[1].data['CarP3']\n",
    "argus3 = malo2014[1].data['ArgP3']\n",
    "abdor3 = malo2014[1].data['ABDorP3']\n",
    "field3 = malo2014[1].data['FldP3']\n",
    "\n",
    "bpic1 = malo2014[1].data['bPicP1']\n",
    "twhya1 = malo2014[1].data['TWAP1']\n",
    "tuchor1 = malo2014[1].data['THAP1']\n",
    "columb1 = malo2014[1].data['ColP1']\n",
    "car1 = malo2014[1].data['CarP1']\n",
    "argus1 = malo2014[1].data['ArgP1']\n",
    "abdor1 = malo2014[1].data['ABDorP1']\n",
    "field1 = malo2014[1].data['FldP1']\n",
    "\n",
    "bpic = malo2014[1].data['bPicP']\n",
    "twhya = malo2014[1].data['TWAP']\n",
    "tuchor = malo2014[1].data['THAP']\n",
    "columb = malo2014[1].data['ColP']\n",
    "car = malo2014[1].data['CarP']\n",
    "argus = malo2014[1].data['ArgP']\n",
    "abdor = malo2014[1].data['ABDorP']\n",
    "field = malo2014[1].data['FldP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups =np.array(['BPMG','TWA','THA','COL','CAR','ARG','ABDMG','FIELD'])\n",
    "groups_num =np.array([mg_ref['group_num'][mg_ref['name']=='BPMG'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='TWA'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='THA'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='COL'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='CAR'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='ARG'][0],\n",
    "                      mg_ref['group_num'][mg_ref['name']=='ABDMG'][0],\n",
    "                      np.nan])\n",
    "age = np.array([mg_ref['age'][mg_ref['name']=='BPMG'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='TWA'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='THA'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='COL'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='CAR'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='ARG'][0],\n",
    "                mg_ref['age'][mg_ref['name']=='ABDMG'][0],\n",
    "                np.nan])\n",
    "age_err = np.array([mg_ref['age_error'][mg_ref['name']=='BPMG'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='TWA'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='THA'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='COL'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='CAR'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='ARG'][0],\n",
    "                    mg_ref['age_error'][mg_ref['name']=='ABDMG'][0], \n",
    "                    np.nan])\n",
    "\n",
    "#groups =np.array(['CARN','HYA','CBER','TAU','BPMG','TWA','THA','COL','CAR','ARG','ABDMG','FIELD'])\n",
    "#age_list = np.array([200,750,562,1.5,24,10,45,42,45,40,149, np.nan ])\n",
    "#age_err_list = np.array([100,100,98,0.5,3,3,4,6,11,10,51, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_stars = []\n",
    "age_err_stars = []\n",
    "group_stars = []\n",
    "group_num_stars = []\n",
    "max_prob_stars = []\n",
    "for i in range(len(bpic3)):\n",
    "    probs = np.array([bpic3[i],twhya3[i],tuchor3[i],columb3[i],car3[i],argus3[i],abdor3[i],field3[i]])\n",
    "    max_prob = max(probs)\n",
    "    if(str(max_prob)=='nan'):\n",
    "        probs = np.array([bpic1[i],twhya1[i],tuchor1[i],columb1[i],car1[i],argus1[i],abdor1[i],field1[i]])\n",
    "        max_prob = max(probs)\n",
    "        if(str(max_prob)=='nan'):\n",
    "            probs = np.array([bpic[i],twhya[i],tuchor[i],columb[i],car[i],argus[i],abdor[i],field[i]])\n",
    "            max_prob = max(probs)\n",
    "    mask = probs == max_prob\n",
    "    age_stars.append(age[mask][0])\n",
    "    age_err_stars.append(age_err[mask][0])\n",
    "    group_stars.append(groups[mask][0])\n",
    "    group_num_stars.append(groups_num[mask][0])\n",
    "    max_prob_stars.append(max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt_malo2014 = src.organize_spt(malo2014[1].data['SPT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_singles_malo2014 = np.array([True if str(x)!='nan' else False for x in spt_malo2014])\n",
    "ra_malo2014 = malo2014[1].data['_RAJ2000'][mask_singles_malo2014]\n",
    "dec_malo2014 = malo2014[1].data['_DEJ2000'][mask_singles_malo2014]\n",
    "N_malo2014 = len(dec_malo2014)\n",
    "spt_malo2014 = spt_malo2014[mask_singles_malo2014]\n",
    "ewha_malo2014 = malo2014[1].data['Ha'][mask_singles_malo2014]\n",
    "ewha_err_malo2014 = 0.5*np.ones(N_malo2014) #From Riaz 2006\n",
    "lhalbol_malo2014 = np.nan*np.ones(N_malo2014)\n",
    "lhalbol_err_malo2014 = np.nan*np.ones(N_malo2014)\n",
    "kmag_malo2014 = np.nan*np.ones(N_malo2014)\n",
    "kmag_err_malo2014 = np.nan*np.ones(N_malo2014)\n",
    "age_malo2014 = np.array(age_stars)[mask_singles_malo2014]\n",
    "age_err_malo2014 = np.array(age_err_stars)[mask_singles_malo2014]\n",
    "group_num_malo2014 = np.array(group_num_stars)[mask_singles_malo2014]\n",
    "group_name_malo2014 = np.array(group_stars)[mask_singles_malo2014]\n",
    "source_num_malo2014 = np.ones(N_malo2014)*source_ref['source_num'][source_ref['source_ref']=='Malo 2014'][0]\n",
    "source_ref_malo2014 = np.array(['Malo 2014' for x in range(N_malo2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "malo2014.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_malo2014) \n",
    "dec_all.append(dec_malo2014)\n",
    "spt_all.append(spt_malo2014)\n",
    "ewha_all.append(ewha_malo2014)\n",
    "ewha_err_all.append(ewha_err_malo2014)\n",
    "lhalbol_all.append(lhalbol_malo2014)\n",
    "lhalbol_err_all.append(lhalbol_err_malo2014)\n",
    "age_all.append(age_malo2014)\n",
    "age_err_all.append(age_err_malo2014)\n",
    "group_num_all.append(group_num_malo2014)\n",
    "group_name_all.append(group_name_malo2014)\n",
    "source_num_all.append(source_num_malo2014)\n",
    "source_ref_all.append(source_ref_malo2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Martin 1996 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mochnacki 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mochnacki2002 = Table.read('Catalogs/Sources/mochnacki2002.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_mochnacki2002 = np.array(mochnacki2002['Ra'])     \n",
    "dec_mochnacki2002 = np.array(mochnacki2002['De'])\n",
    "N_mochnacki2002 = len(dec_mochnacki2002)\n",
    "spt_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "ewha_mochnacki2002 = np.array(mochnacki2002['EWHa'])*(-1)\n",
    "ewha_err_mochnacki2002 = np.array(mochnacki2002['EWHa_err'])\n",
    "lhalbol_mochnacki2002 = np.array(mochnacki2002['LHaLbol'])\n",
    "lhalbol_err_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "age_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "age_err_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "\n",
    "group_num_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "group_name_mochnacki2002 = np.ones(N_mochnacki2002)*np.nan\n",
    "source_num_mochnacki2002 = np.ones(N_mochnacki2002)*source_ref['source_num'][source_ref['source_ref']=='Mochnacki 2002'][0]\n",
    "source_ref_mochnacki2002 = np.array(['Mochnacki 2002' for x in range(N_mochnacki2002)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_mochnacki2002) \n",
    "dec_all.append(dec_mochnacki2002)\n",
    "spt_all.append(spt_mochnacki2002)\n",
    "ewha_all.append(ewha_mochnacki2002)\n",
    "ewha_err_all.append(ewha_err_mochnacki2002)\n",
    "lhalbol_all.append(lhalbol_mochnacki2002)\n",
    "lhalbol_err_all.append(lhalbol_err_mochnacki2002)\n",
    "age_all.append(age_mochnacki2002)\n",
    "age_err_all.append(age_err_mochnacki2002)\n",
    "group_num_all.append(group_num_mochnacki2002)\n",
    "group_name_all.append(group_name_mochnacki2002)\n",
    "source_num_all.append(source_num_mochnacki2002)\n",
    "source_ref_all.append(source_ref_mochnacki2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mohanty 2003 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mohanty 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mohanty2005 = Table.read('Catalogs/Sources/mohanty2005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_mohanty2005 = np.array(mohanty2005['Ra'])     \n",
    "dec_mohanty2005 = np.array(mohanty2005['De'])\n",
    "N_mohanty2005 = len(dec_mohanty2005)\n",
    "spt_mohanty2005 = np.array(mohanty2005['SpT'])     \n",
    "ewha_mohanty2005 = np.array(mohanty2005['EWHa'])     \n",
    "ewha_err_mohanty2005 = np.array(mohanty2005['EWHa_err'])     \n",
    "lhalbol_mohanty2005 = np.ones(N_mohanty2005)*np.nan\n",
    "lhalbol_err_mohanty2005 = np.ones(N_mohanty2005)*np.nan\n",
    "\n",
    "age_mohanty2005 = np.ones(N_mohanty2005)*np.nan\n",
    "age_err_mohanty2005 = np.ones(N_mohanty2005)*np.nan\n",
    "group_num_mohanty2005 = np.ones(N_mohanty2005)*np.nan\n",
    "\n",
    "for x in ['ROPH','TAU','IC 348','Cha I','R CrA','USCO','TWA']:\n",
    "    mask1 = mohanty2005['Group'] == x\n",
    "    n_mask = len(mohanty2005['Group'][mask1])\n",
    "    age_mohanty2005[mask1] = np.ones(n_mask)*mg_ref['age'][mg_ref['name']==x][0]\n",
    "    age_err_mohanty2005[mask1] = np.ones(n_mask)*mg_ref['age_error'][mg_ref['name']==x][0]\n",
    "    group_num_mohanty2005[mask1] = np.ones(n_mask)*mg_ref['group_num'][mg_ref['name']==x][0]\n",
    "    \n",
    "\n",
    "group_name_mohanty2005 = np.array(mohanty2005['Group'])\n",
    "source_num_mohanty2005 = np.ones(N_mohanty2005)*source_ref['source_num'][source_ref['source_ref']=='Mohanty 2005'][0]\n",
    "source_ref_mohanty2005 = np.array(['Mohanty 2005' for x in range(N_mohanty2005)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_mohanty2005) \n",
    "dec_all.append(dec_mohanty2005)\n",
    "spt_all.append(spt_mohanty2005)\n",
    "ewha_all.append(ewha_mohanty2005)\n",
    "ewha_err_all.append(ewha_err_mohanty2005)\n",
    "lhalbol_all.append(lhalbol_mohanty2005)\n",
    "lhalbol_err_all.append(lhalbol_err_mohanty2005)\n",
    "age_all.append(age_mohanty2005)\n",
    "age_err_all.append(age_err_mohanty2005)\n",
    "group_num_all.append(group_num_mohanty2005)\n",
    "group_name_all.append(group_name_mohanty2005)\n",
    "source_num_all.append(source_num_mohanty2005)\n",
    "source_ref_all.append(source_ref_mohanty2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Murphy 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_murphy2010 = np.array([136.3786250,138.3931250,148.9132917,135.7139792,151.3334542])     \n",
    "dec_murphy2010 = np.array([-81.5825556,-75.8336083,-76.3699722,-77.9930139,-77.8117342])\n",
    "N_murphy2010 = len(dec_murphy2010)\n",
    "spt_murphy2010 = np.array([4.9,4.8,4.1,3,1])\n",
    "ewha_murphy2010 = np.array([-9,-8,-5,-2,-4])*(-1)\n",
    "ewha_err_murphy2010 = np.ones(N_murphy2010)*1\n",
    "lhalbol_murphy2010 = np.ones(N_murphy2010)*np.nan\n",
    "lhalbol_err_murphy2010 = np.ones(N_murphy2010)*np.nan\n",
    "age_murphy2010 = np.ones(N_murphy2010)*mg_ref['age'][mg_ref['name']=='ETAC'][0]\n",
    "age_err_murphy2010 = np.ones(N_murphy2010)*mg_ref['age_error'][mg_ref['name']=='ETAC'][0]\n",
    "\n",
    "group_num_murphy2010 = np.ones(N_murphy2010)*mg_ref['group_num'][mg_ref['name']=='ETAC'][0]\n",
    "group_name_murphy2010 = np.array(['ETAC' for i in range(N_murphy2010)])\n",
    "source_num_murphy2010 = np.ones(N_murphy2010)*source_ref['source_num'][source_ref['source_ref']=='Murphy 2010'][0]\n",
    "source_ref_murphy2010 = np.array(['Murphy 2010' for x in range(N_murphy2010)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_murphy2010) \n",
    "dec_all.append(dec_murphy2010)\n",
    "spt_all.append(spt_murphy2010)\n",
    "ewha_all.append(ewha_murphy2010)\n",
    "ewha_err_all.append(ewha_err_murphy2010)\n",
    "lhalbol_all.append(lhalbol_murphy2010)\n",
    "lhalbol_err_all.append(lhalbol_err_murphy2010)\n",
    "age_all.append(age_murphy2010)\n",
    "age_err_all.append(age_err_murphy2010)\n",
    "group_num_all.append(group_num_murphy2010)\n",
    "group_name_all.append(group_name_murphy2010)\n",
    "source_num_all.append(source_num_murphy2010)\n",
    "source_ref_all.append(source_ref_murphy2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton2017 = fits.open('Catalogs/Sources/Newton2017.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_newton2017 = newton2017[1].data['RAJ2000']     \n",
    "dec_newton2017 = newton2017[1].data['DEJ2000']\n",
    "N_newton2017 = len(dec_newton2017)\n",
    "spt_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "ewha_newton2017 = newton2017[1].data['EWHa-u']*(-1)\n",
    "ewha_err_newton2017 = newton2017[1].data['e_EWHa-u']\n",
    "lhalbol_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "lhalbol_err_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "age_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "age_err_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "\n",
    "group_num_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "group_name_newton2017 = np.ones(N_newton2017)*np.nan\n",
    "source_num_newton2017 = []\n",
    "source_ref_newton2017 = []\n",
    "\n",
    "for i in range(N_newton2017):\n",
    "    mask = newton2017[1].data['r_EWHa-u'][i] == source_ref['ref_link']\n",
    "    if(any(mask)):\n",
    "        source_num_newton2017.append(source_ref['source_num'][mask][0])\n",
    "        source_ref_newton2017.append(source_ref['source_ref'][mask][0])\n",
    "    else:\n",
    "        #print(newton2017[1].data['r_EWHa-u'][i])\n",
    "        source_num_newton2017.append(source_ref['source_num'][source_ref['source_ref']=='Newton 2017'][0])\n",
    "        source_ref_newton2017.append('Newton 2017')   \n",
    "        \n",
    "source_num_newton2017 = np.array(source_num_newton2017)\n",
    "source_ref_newton2017 = np.array(source_ref_newton2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_newton2017) \n",
    "dec_all.append(dec_newton2017)\n",
    "spt_all.append(spt_newton2017)\n",
    "ewha_all.append(ewha_newton2017)\n",
    "ewha_err_all.append(ewha_err_newton2017)\n",
    "lhalbol_all.append(lhalbol_newton2017)\n",
    "lhalbol_err_all.append(lhalbol_err_newton2017)\n",
    "age_all.append(age_newton2017)\n",
    "age_err_all.append(age_err_newton2017)\n",
    "group_num_all.append(group_num_newton2017)\n",
    "group_name_all.append(group_name_newton2017)\n",
    "source_num_all.append(source_num_newton2017)\n",
    "source_ref_all.append(source_ref_newton2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton2017.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phan-Bao 2006 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reid 1995 (with Newton 2017) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reid 2002 (with Newton 2017) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reid 2007 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reiners 2007 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reiners 2008 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reiners 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reiners2010 = Table.read('Catalogs/Sources/Reiners2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_reiners2010,dec_reiners2010 = [],[]\n",
    "for x in reiners2010['2mass']:\n",
    "    ra_name='none'\n",
    "    dec_name='none'\n",
    "    if('A' in x or 'B' in x):\n",
    "        ra_reiners2010.append(np.nan)\n",
    "        dec_reiners2010.append(np.nan)\n",
    "    elif('+' in x):\n",
    "        ra,dec = x.split('+')\n",
    "        if(len(ra)==8 or len(ra)==7):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\n",
    "        elif(len(ra)==6):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\n",
    "        else:\n",
    "            print(ra)\n",
    "            \n",
    "        if(len(dec)==8 or len(dec)==7):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\n",
    "        elif(len(dec)==6):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\n",
    "        else:\n",
    "            print(dec)\n",
    "        star_name = ra_name+'+'+dec_name\n",
    "        #print(star_name)\n",
    "        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\n",
    "        ra_reiners2010.append(coord.ra.deg)\n",
    "        dec_reiners2010.append(coord.dec.deg)\n",
    "    elif('-' in x):\n",
    "        ra,dec = x.split('-')\n",
    "        if(len(ra)==8 or len(ra)==7):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\n",
    "        elif(len(ra)==6):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\n",
    "        else:\n",
    "            print(ra)\n",
    "            \n",
    "        if(len(dec)==8 or len(dec)==7):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\n",
    "        elif(len(dec)==6):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\n",
    "        else:\n",
    "            print(dec)\n",
    "        star_name = ra_name+'-'+dec_name\n",
    "        #print(star_name)\n",
    "        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\n",
    "        ra_reiners2010.append(coord.ra.deg)\n",
    "        dec_reiners2010.append(coord.dec.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_reiners2010 = np.array(ra_reiners2010)\n",
    "dec_reiners2010 = np.array(dec_reiners2010)\n",
    "N_reiners2010 = len(dec_reiners2010)\n",
    "spt_reiners2010 = np.array(reiners2010['spt'])\n",
    "ewha_reiners2010 = np.array(reiners2010['ewha'])\n",
    "ewha_err_reiners2010 = np.array(reiners2010['ewha_err'])\n",
    "lhalbol_reiners2010 = np.array(reiners2010['Lhalbol'])\n",
    "lhalbol_err_reiners2010 = np.ones(N_reiners2010)*np.nan\n",
    "age_reiners2010 = np.ones(N_reiners2010)*np.nan\n",
    "age_err_reiners2010 = np.ones(N_reiners2010)*np.nan\n",
    "\n",
    "group_num_reiners2010 = np.ones(N_reiners2010)*np.nan\n",
    "group_name_reiners2010 = np.ones(N_reiners2010)*np.nan\n",
    "source_num_reiners2010 = np.ones(N_reiners2010)*source_ref['source_num'][source_ref['source_ref']=='Reiners 2010'][0]\n",
    "source_ref_reiners2010 = np.array(['Reiners 2010' for x in range(N_reiners2010)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_reiners2010) \n",
    "dec_all.append(dec_reiners2010)\n",
    "spt_all.append(spt_reiners2010)\n",
    "ewha_all.append(ewha_reiners2010)\n",
    "ewha_err_all.append(ewha_err_reiners2010)\n",
    "lhalbol_all.append(lhalbol_reiners2010)\n",
    "lhalbol_err_all.append(lhalbol_err_reiners2010)\n",
    "age_all.append(age_reiners2010)\n",
    "age_err_all.append(age_err_reiners2010)\n",
    "group_num_all.append(group_num_reiners2010)\n",
    "group_name_all.append(group_name_reiners2010)\n",
    "source_num_all.append(source_num_reiners2010)\n",
    "source_ref_all.append(source_ref_reiners2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riaz 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nriaz2006 = Table.read('Catalogs/Sources/Riaz2006.csv')\\nra_riaz2006,dec_riaz2006 = [],[]\\nfor x in riaz2006['2MASS Name']:\\n    ra_name='none'\\n    dec_name='none'\\n    if('A' in x or 'B' in x):\\n        ra_riaz2006.append(np.nan)\\n        dec_riaz2006.append(np.nan)\\n    elif('+' in x):\\n        ra,dec = x.split('+')\\n        if(len(ra)==8 or len(ra)==7):\\n            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\\n        elif(len(ra)==6):\\n            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\\n        else:\\n            print(ra)\\n            \\n        if(len(dec)==8 or len(dec)==7):\\n            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\\n        elif(len(dec)==6):\\n            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\\n        else:\\n            print(dec)\\n        star_name = ra_name+'+'+dec_name\\n        #print(star_name)\\n        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\\n        ra_riaz2006.append(coord.ra.deg)\\n        dec_riaz2006.append(coord.dec.deg)\\n    elif('-' in x):\\n        ra,dec = x.split('-')\\n        if(len(ra)==8 or len(ra)==7):\\n            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\\n        elif(len(ra)==6):\\n            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\\n        else:\\n            print(ra)\\n            \\n        if(len(dec)==8 or len(dec)==7):\\n            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\\n        elif(len(dec)==6):\\n            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\\n        else:\\n            print(dec)\\n        star_name = ra_name+'-'+dec_name\\n        #print(star_name)\\n        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\\n        ra_riaz2006.append(coord.ra.deg)\\n        dec_riaz2006.append(coord.dec.deg)\\nriaz2006['ra'] = np.array(ra_riaz2006)\\nriaz2006['dec'] = np.array(dec_riaz2006)\\nriaz2006.write('Catalogs/Sources/Riaz2006_w_radec.fits',format='fits',overwrite=True)\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "riaz2006 = Table.read('Catalogs/Sources/Riaz2006.csv')\n",
    "ra_riaz2006,dec_riaz2006 = [],[]\n",
    "for x in riaz2006['2MASS Name']:\n",
    "    ra_name='none'\n",
    "    dec_name='none'\n",
    "    if('A' in x or 'B' in x):\n",
    "        ra_riaz2006.append(np.nan)\n",
    "        dec_riaz2006.append(np.nan)\n",
    "    elif('+' in x):\n",
    "        ra,dec = x.split('+')\n",
    "        if(len(ra)==8 or len(ra)==7):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\n",
    "        elif(len(ra)==6):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\n",
    "        else:\n",
    "            print(ra)\n",
    "            \n",
    "        if(len(dec)==8 or len(dec)==7):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\n",
    "        elif(len(dec)==6):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\n",
    "        else:\n",
    "            print(dec)\n",
    "        star_name = ra_name+'+'+dec_name\n",
    "        #print(star_name)\n",
    "        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\n",
    "        ra_riaz2006.append(coord.ra.deg)\n",
    "        dec_riaz2006.append(coord.dec.deg)\n",
    "    elif('-' in x):\n",
    "        ra,dec = x.split('-')\n",
    "        if(len(ra)==8 or len(ra)==7):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]+'.'+ra[6:]\n",
    "        elif(len(ra)==6):\n",
    "            ra_name = ra[:2]+':'+ra[2:4]+':'+ra[4:6]\n",
    "        else:\n",
    "            print(ra)\n",
    "            \n",
    "        if(len(dec)==8 or len(dec)==7):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]+'.'+dec[6:]\n",
    "        elif(len(dec)==6):\n",
    "            dec_name = dec[:2]+':'+dec[2:4]+':'+dec[4:6]\n",
    "        else:\n",
    "            print(dec)\n",
    "        star_name = ra_name+'-'+dec_name\n",
    "        #print(star_name)\n",
    "        coord = SkyCoord(star_name, unit=(u.hourangle, u.deg))\n",
    "        ra_riaz2006.append(coord.ra.deg)\n",
    "        dec_riaz2006.append(coord.dec.deg)\n",
    "riaz2006['ra'] = np.array(ra_riaz2006)\n",
    "riaz2006['dec'] = np.array(dec_riaz2006)\n",
    "riaz2006.write('Catalogs/Sources/Riaz2006_w_radec.fits',format='fits',overwrite=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "riaz2006 = Table.read('Catalogs/Sources/Riaz2006_w_radec.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_riaz2006 = np.array(riaz2006['ra'])\n",
    "dec_riaz2006 = np.array(riaz2006['dec'])\n",
    "N_riaz2006 = len(dec_riaz2006)\n",
    "spt_riaz2006 = src.organize_spt(riaz2006['SpT'])\n",
    "ewha_riaz2006 = np.array(riaz2006['EWHa'])\n",
    "ewha_err_riaz2006 = np.ones(N_riaz2006)*0.5 #says the paper\n",
    "lhalbol_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "lhalbol_err_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "age_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "age_err_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "\n",
    "group_num_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "group_name_riaz2006 = np.ones(N_riaz2006)*np.nan\n",
    "source_num_riaz2006 = np.ones(N_riaz2006)*source_ref['source_num'][source_ref['source_ref']=='Riaz 2006'][0]\n",
    "source_ref_riaz2006 = np.array(['Riaz 2006' for x in range(N_riaz2006)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_riaz2006) \n",
    "dec_all.append(dec_riaz2006)\n",
    "spt_all.append(spt_riaz2006)\n",
    "ewha_all.append(ewha_riaz2006)\n",
    "ewha_err_all.append(ewha_err_riaz2006)\n",
    "lhalbol_all.append(lhalbol_riaz2006)\n",
    "lhalbol_err_all.append(lhalbol_err_riaz2006)\n",
    "age_all.append(age_riaz2006)\n",
    "age_err_all.append(age_err_riaz2006)\n",
    "group_num_all.append(group_num_riaz2006)\n",
    "group_name_all.append(group_name_riaz2006)\n",
    "source_num_all.append(source_num_riaz2006)\n",
    "source_ref_all.append(source_ref_riaz2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riedel 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "riedel2014_1 = Table.read('Catalogs/Sources/Riedel2014_1.fit')\n",
    "riedel2014_2 = Table.read('Catalogs/Sources/Riedel2014_2.fit')\n",
    "riedel2014_3 = Table.read('Catalogs/Sources/Riedel2014_3.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = riedel2014_2['Name']==riedel2014_2['Name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_riedel2014,dec_riedel2014,spt_riedel2014 = [],[],[]\n",
    "group_num_riedel2014,group_name_riedel2014=[],[]\n",
    "age_riedel2014,age_err_riedel2014=[],[]\n",
    "for x in riedel2014_1['Name']:\n",
    "    mask_name = riedel2014_2['Name'] == x\n",
    "    spt_riedel2014.append(riedel2014_2['SpT'][mask_name][0])\n",
    "    ra_riedel2014.append(riedel2014_2['RAJ2000'][mask_name][0])\n",
    "    dec_riedel2014.append(riedel2014_2['DEJ2000'][mask_name][0])\n",
    "for x in riedel2014_1['Name']:\n",
    "    mask_name = riedel2014_3['Name'] == x\n",
    "    if(riedel2014_3['KAsso'][mask_name][0]=='{beta} Pic'):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='BPMG'][0])\n",
    "        group_name_riedel2014.append('BPMG')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='BPMG'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='BPMG'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='Carina    '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='CAR'][0])\n",
    "        group_name_riedel2014.append('CAR')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='CAR'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='CAR'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='AB Dor    '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='ABDMG'][0])\n",
    "        group_name_riedel2014.append('ABDMG')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='ABDMG'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='ABDMG'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='Columba   '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='COL'][0])\n",
    "        group_name_riedel2014.append('COL')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='COL'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='COL'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='Ursa Major'):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='UMA'][0])\n",
    "        group_name_riedel2014.append('UMA')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='UMA'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='UMA'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='TW Hya    '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='TWA'][0])\n",
    "        group_name_riedel2014.append('TWA')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='TWA'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='TWA'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='Hyades    '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='HYA'][0])\n",
    "        group_name_riedel2014.append('HYA')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='HYA'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='HYA'][0])\n",
    "    elif(riedel2014_3['KAsso'][mask_name][0]=='Argus     '):\n",
    "        group_num_riedel2014.append(mg_ref['group_num'][mg_ref['name']=='ARG'][0])\n",
    "        group_name_riedel2014.append('ARG')\n",
    "        age_riedel2014.append(mg_ref['age'][mg_ref['name']=='ARG'][0])\n",
    "        age_err_riedel2014.append(mg_ref['age_error'][mg_ref['name']=='ARG'][0])\n",
    "    else:\n",
    "        group_num_riedel2014.append(np.nan)\n",
    "        group_name_riedel2014.append(np.nan)\n",
    "        age_riedel2014.append(np.nan)\n",
    "        age_err_riedel2014.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_riedel2014 = np.array(ra_riedel2014)\n",
    "dec_riedel2014 = np.array(dec_riedel2014)\n",
    "N_riedel2014 = len(ra_riedel2014)\n",
    "spt_riedel2014 = src.organize_spt(np.array(spt_riedel2014))\n",
    "ewha_riedel2014 = riedel2014_1['EWHa']*-1\n",
    "ewha_err_riedel2014 = np.ones(N_riedel2014)*0.2 #says in the paper\n",
    "lhalbol_riedel2014 = np.ones(N_riedel2014)*np.nan\n",
    "lhalbol_err_riedel2014 = np.ones(N_riedel2014)*np.nan\n",
    "kmag_riedel2014 = np.ones(N_riedel2014)*np.nan\n",
    "kmag_err_riedel2014 = np.ones(N_riedel2014)*np.nan\n",
    "age_riedel2014 = np.array(age_riedel2014)\n",
    "age_err_riedel2014 = np.array(age_err_riedel2014)\n",
    "\n",
    "group_num_riedel2014 = np.array(group_num_riedel2014)\n",
    "group_name_riedel2014 = np.array(group_name_riedel2014)\n",
    "source_num_riedel2014 = np.ones(N_riedel2014)*source_ref['source_num'][source_ref['source_ref']=='Riedel 2014'][0]\n",
    "source_ref_riedel2014 = np.array(['Riedel 2014' for x in range(N_riedel2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_riedel2014) \n",
    "dec_all.append(dec_riedel2014)\n",
    "spt_all.append(spt_riedel2014)\n",
    "ewha_all.append(ewha_riedel2014)\n",
    "ewha_err_all.append(ewha_err_riedel2014)\n",
    "lhalbol_all.append(lhalbol_riedel2014)\n",
    "lhalbol_err_all.append(lhalbol_err_riedel2014)\n",
    "age_all.append(age_riedel2014)\n",
    "age_err_all.append(age_err_riedel2014)\n",
    "group_num_all.append(group_num_riedel2014)\n",
    "group_name_all.append(group_name_riedel2014)\n",
    "source_num_all.append(source_num_riedel2014)\n",
    "source_ref_all.append(source_ref_riedel2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodriguez 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodriguez2014 = Table.read('Catalogs/Sources/Rodriguez2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_rodriguez2014,dec_rodriguez2014 = np.array(rodriguez2014['Ra']),np.array(rodriguez2014['De'])\n",
    "N_rodriguez2014 = len(dec_rodriguez2014)\n",
    "spt_rodriguez2014 = np.array(rodriguez2014['SpT'])\n",
    "ewha_rodriguez2014 = np.array(rodriguez2014['HaEW'])*(-1)\n",
    "ewha_err_rodriguez2014 = np.array(rodriguez2014['HaEW_err'])\n",
    "lhalbol_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "lhalbol_err_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "kmag_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "kmag_err_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "age_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "age_err_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "\n",
    "group_num_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "group_name_rodriguez2014 = np.ones(N_rodriguez2014)*np.nan\n",
    "source_num_rodriguez2014 = np.ones(N_rodriguez2014)*source_ref['source_num'][source_ref['source_ref']=='Rodriguez 2014'][0]\n",
    "source_ref_rodriguez2014 = np.array(['Rodriguez 2014' for x in range(N_rodriguez2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_rodriguez2014) \n",
    "dec_all.append(dec_rodriguez2014)\n",
    "spt_all.append(spt_rodriguez2014)\n",
    "ewha_all.append(ewha_rodriguez2014)\n",
    "ewha_err_all.append(ewha_err_rodriguez2014)\n",
    "lhalbol_all.append(lhalbol_rodriguez2014)\n",
    "lhalbol_err_all.append(lhalbol_err_rodriguez2014)\n",
    "age_all.append(age_rodriguez2014)\n",
    "age_err_all.append(age_err_rodriguez2014)\n",
    "group_num_all.append(group_num_rodriguez2014)\n",
    "group_name_all.append(group_name_rodriguez2014)\n",
    "source_num_all.append(source_num_rodriguez2014)\n",
    "source_ref_all.append(source_ref_rodriguez2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schneider 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "schneider2019 = Table.read('Catalogs/Sources/Schneider2019.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_schneider2019 = np.array(np.array(schneider2019['_RA']))\n",
    "dec_schneider2019 = np.array(np.array(schneider2019['_DE']))\n",
    "N_schneider2019 = len(dec_schneider2019)\n",
    "spt_schneider2019 = src.organize_spt(np.array([str(x).replace(\" \", \"\") for x in schneider2019['SpType']]))\n",
    "ewha_schneider2019 = np.array(schneider2019['EW_Ha_'])*(-1)\n",
    "ewha_err_schneider2019 = np.ones(N_schneider2019)*0.1 #They paper has similar resolution to Shkolnik 2017, so using the same error\n",
    "lhalbol_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "lhalbol_err_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "age_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "age_err_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "\n",
    "group_num_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "group_name_schneider2019 = np.ones(N_schneider2019)*np.nan\n",
    "source_num_schneider2019 = np.ones(N_schneider2019)*source_ref['source_num'][source_ref['source_ref']=='Schneider 2019'][0]\n",
    "source_ref_schneider2019 = np.array(['Schneider 2019' for x in range(N_schneider2019)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_schneider2019) \n",
    "dec_all.append(dec_schneider2019)\n",
    "spt_all.append(spt_schneider2019)\n",
    "ewha_all.append(ewha_schneider2019)\n",
    "ewha_err_all.append(ewha_err_schneider2019)\n",
    "lhalbol_all.append(lhalbol_schneider2019)\n",
    "lhalbol_err_all.append(lhalbol_err_schneider2019)\n",
    "age_all.append(age_schneider2019)\n",
    "age_err_all.append(age_err_schneider2019)\n",
    "group_num_all.append(group_num_schneider2019)\n",
    "group_name_all.append(group_name_schneider2019)\n",
    "source_num_all.append(source_num_schneider2019)\n",
    "source_ref_all.append(source_ref_schneider2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shkolnik 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "shkolnik2009 = fits.open('Catalogs/Sources/shkolnik2009.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_shkolnik2009 = np.array(shkolnik2009[1].data['_RAJ2000'])\n",
    "dec_shkolnik2009 = np.array(shkolnik2009[1].data['_DEJ2000'])\n",
    "N_shkolnik2009 = len(ra_shkolnik2009)\n",
    "spt_shkolnik2009 = shkolnik2009[1].data['SpT']\n",
    "ewha_shkolnik2009 = shkolnik2009[1].data['W_Ha_']*-1\n",
    "ewha_err_shkolnik2009 = np.ones(N_shkolnik2009)*0.45 #says in the paper\n",
    "lhalbol_shkolnik2009 = np.ones(N_shkolnik2009)*np.nan\n",
    "lhalbol_err_shkolnik2009 = np.ones(N_shkolnik2009)*np.nan\n",
    "age_shkolnik2009 = shkolnik2009[1].data['Age']  \n",
    "age_err_shkolnik2009 = np.ones(N_shkolnik2009)*np.nan\n",
    "\n",
    "group_num_shkolnik2009 = np.ones(N_shkolnik2009)*np.nan\n",
    "group_name_shkolnik2009 = np.ones(N_shkolnik2009)*np.nan\n",
    "source_num_shkolnik2009 = np.ones(N_shkolnik2009)*source_ref['source_num'][source_ref['source_ref']=='Shkolnik 2009'][0]\n",
    "source_ref_shkolnik2009 = np.array(['Shkolnik 2009' for x in range(N_shkolnik2009)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "shkolnik2009.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_shkolnik2009) \n",
    "dec_all.append(dec_shkolnik2009)\n",
    "spt_all.append(spt_shkolnik2009)\n",
    "ewha_all.append(ewha_shkolnik2009)\n",
    "ewha_err_all.append(ewha_err_shkolnik2009)\n",
    "lhalbol_all.append(lhalbol_shkolnik2009)\n",
    "lhalbol_err_all.append(lhalbol_err_shkolnik2009)\n",
    "age_all.append(age_shkolnik2009)\n",
    "age_err_all.append(age_err_shkolnik2009)\n",
    "group_num_all.append(group_num_shkolnik2009)\n",
    "group_name_all.append(group_name_shkolnik2009)\n",
    "source_num_all.append(source_num_shkolnik2009)\n",
    "source_ref_all.append(source_ref_shkolnik2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shkolnik 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_shkolnik2011 = np.array([167.31,167.6166667,167.6158333,172.98,160.63,173.1719413,173.1715542,188.77,170.27,\n",
    "                            168.36,188.59,188.73,154.36,181.86,181.7953750,186.7139583])\n",
    "dec_shkolnik2011 = np.array([-30.03,-37.5308333,-37.5313889,-34.61,-33.67,-26.8655449,-26.8691975,-41.61,-38.75,\n",
    "                             -45.40,-48.26,-45.64,-53.91,-32.78,-32.5149222,-33.2701306])\n",
    "N_shkolnik2011 = len(ra_shkolnik2011)\n",
    "spt_shkolnik2011 = np.ones(N_shkolnik2011)*np.nan\n",
    "ewha_shkolnik2011 = np.array([-1.72,-40.89,-4.26,-6.37,-5.39,-5.04,-6.21,-5.46,-5.10,-5.68,\n",
    "                              -9.64,-3.08,-10.48,8.12,-114.8,-12.6])*-1\n",
    "ewha_err_shkolnik2011 = np.array([0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,\n",
    "                                  0.05,0.05,0.5,0.5])#says in the paper\n",
    "lhalbol_shkolnik2011 = np.ones(N_shkolnik2011)*np.nan\n",
    "lhalbol_err_shkolnik2011 = np.ones(N_shkolnik2011)*np.nan\n",
    "age_shkolnik2011 = np.ones(N_shkolnik2011)*mg_ref['age'][mg_ref['name']=='TWA'][0]\n",
    "age_err_shkolnik2011 = np.ones(N_shkolnik2011)*mg_ref['age_error'][mg_ref['name']=='TWA'][0]\n",
    "\n",
    "group_num_shkolnik2011 = np.ones(N_shkolnik2011)*mg_ref['group_num'][mg_ref['name']=='TWA'][0]\n",
    "group_name_shkolnik2011 = np.array(['TWA' for i in range(N_shkolnik2011)])\n",
    "source_num_shkolnik2011 = np.ones(N_shkolnik2011)*source_ref['source_num'][source_ref['source_ref']=='Shkolnik 2011'][0]\n",
    "source_ref_shkolnik2011 = np.array(['Shkolnik 2011' for x in range(N_shkolnik2011)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_shkolnik2011) \n",
    "dec_all.append(dec_shkolnik2011)\n",
    "spt_all.append(spt_shkolnik2011)\n",
    "ewha_all.append(ewha_shkolnik2011)\n",
    "ewha_err_all.append(ewha_err_shkolnik2011)\n",
    "lhalbol_all.append(lhalbol_shkolnik2011)\n",
    "lhalbol_err_all.append(lhalbol_err_shkolnik2011)\n",
    "age_all.append(age_shkolnik2011)\n",
    "age_err_all.append(age_err_shkolnik2011)\n",
    "group_num_all.append(group_num_shkolnik2011)\n",
    "group_name_all.append(group_name_shkolnik2011)\n",
    "source_num_all.append(source_num_shkolnik2011)\n",
    "source_ref_all.append(source_ref_shkolnik2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shkolnik 2017: BPMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "shkolnik2017 = fits.open('Catalogs/Sources/Shkolnik2017.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid keyword for column 8: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 10: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 12: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 13: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 16: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n",
      "WARNING: VerifyWarning: Invalid keyword for column 18: ASCII table null option (TNULLn) is longer than the column's character width and will be truncated (got '-32768'). [astropy.io.fits.column]\n"
     ]
    }
   ],
   "source": [
    "spt_shkolnik2017 = src.organize_spt(shkolnik2017[1].data['SpType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mem = shkolnik2017[1].data['BPMG']\n",
    "member = np.array([True if x=='Y' else False for x in list_mem])\n",
    "\n",
    "member_single_shkolnik2017 = member * np.array([True if str(x)!='nan' else False for x in spt_shkolnik2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_shkolnik2017 = shkolnik2017[1].data['_RAJ2000'][member_single_shkolnik2017]\n",
    "dec_shkolnik2017 = shkolnik2017[1].data['_DEJ2000'][member_single_shkolnik2017]\n",
    "N_shkolnik2017 = len(dec_shkolnik2017)\n",
    "spt_shkolnik2017 = spt_shkolnik2017[member_single_shkolnik2017]\n",
    "ewha_shkolnik2017 = shkolnik2017[1].data['EW_Ha_'][member_single_shkolnik2017]*(-1)\n",
    "ewha_err_shkolnik2017 = np.ones(N_shkolnik2017)*0.1 #says in the paper\n",
    "lhalbol_shkolnik2017 = np.ones(N_shkolnik2017)*np.nan\n",
    "lhalbol_err_shkolnik2017 = np.ones(N_shkolnik2017)*np.nan\n",
    "kmag_shkolnik2017 = np.ones(N_shkolnik2017)*np.nan\n",
    "kmag_err_shkolnik2017 = np.ones(N_shkolnik2017)*np.nan\n",
    "age_shkolnik2017 = np.ones(N_shkolnik2017)*mg_ref['age'][mg_ref['name']=='BPMG'][0]\n",
    "age_err_shkolnik2017 = np.ones(N_shkolnik2017)*mg_ref['age_error'][mg_ref['name']=='BPMG'][0]\n",
    "\n",
    "group_num_shkolnik2017 = np.ones(N_shkolnik2017)*mg_ref['group_num'][mg_ref['name']=='BPMG'][0]\n",
    "group_name_shkolnik2017 = np.array(['BPMG' for i in range(N_shkolnik2017)])\n",
    "source_num_shkolnik2017 = np.ones(N_shkolnik2017)*source_ref['source_num'][source_ref['source_ref']=='Shkolnik 2017'][0]\n",
    "source_ref_shkolnik2017 = np.array(['Shkolnik 2017' for x in range(N_shkolnik2017)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "shkolnik2017.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_shkolnik2017) \n",
    "dec_all.append(dec_shkolnik2017)\n",
    "spt_all.append(spt_shkolnik2017)\n",
    "ewha_all.append(ewha_shkolnik2017)\n",
    "ewha_err_all.append(ewha_err_shkolnik2017)\n",
    "lhalbol_all.append(lhalbol_shkolnik2017)\n",
    "lhalbol_err_all.append(lhalbol_err_shkolnik2017)\n",
    "age_all.append(age_shkolnik2017)\n",
    "age_err_all.append(age_err_shkolnik2017)\n",
    "group_num_all.append(group_num_shkolnik2017)\n",
    "group_name_all.append(group_name_shkolnik2017)\n",
    "source_num_all.append(source_num_shkolnik2017)\n",
    "source_ref_all.append(source_ref_shkolnik2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slesnick 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "slesnick2006 = fits.open('Catalogs/Sources/Slesnick2006.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt_slesnick2006 = np.array([x.replace(\":\",\"\") for x in slesnick2006[1].data['SpT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_slesnick2006 = slesnick2006[1].data['_RA']     \n",
    "dec_slesnick2006 = slesnick2006[1].data['_DE']\n",
    "N_slesnick2006 = len(dec_slesnick2006)\n",
    "spt_slesnick2006 = src.organize_spt(spt_slesnick2006)\n",
    "ewha_slesnick2006 = slesnick2006[1].data['EWHa']*(-1)\n",
    "ewha_err_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "lhalbol_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "lhalbol_err_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "age_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "age_err_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "\n",
    "group_num_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "group_name_slesnick2006 = np.ones(N_slesnick2006)*np.nan\n",
    "source_num_slesnick2006 = np.ones(N_slesnick2006)*source_ref['source_num'][source_ref['source_ref']=='Slesnick 2006'][0]\n",
    "source_ref_slesnick2006 = np.array(['Slesnick 2006' for x in range(N_slesnick2006)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_slesnick2006) \n",
    "dec_all.append(dec_slesnick2006)\n",
    "spt_all.append(spt_slesnick2006)\n",
    "ewha_all.append(ewha_slesnick2006)\n",
    "ewha_err_all.append(ewha_err_slesnick2006)\n",
    "lhalbol_all.append(lhalbol_slesnick2006)\n",
    "lhalbol_err_all.append(lhalbol_err_slesnick2006)\n",
    "age_all.append(age_slesnick2006)\n",
    "age_err_all.append(age_err_slesnick2006)\n",
    "group_num_all.append(group_num_slesnick2006)\n",
    "group_name_all.append(group_name_slesnick2006)\n",
    "source_num_all.append(source_num_slesnick2006)\n",
    "source_ref_all.append(source_ref_slesnick2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "slesnick2006.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slesnick 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "slesnick2008_1 = fits.open('Catalogs/Sources/Slesnick2008_1.fit')\n",
    "#slesnick2008_2 = fits.open('Catalogs/Sources/Slesnick2008_2.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_slesnick2008 = slesnick2008_1[1].data['_RA']     \n",
    "dec_slesnick2008 = slesnick2008_1[1].data['_DE']\n",
    "N_slesnick2008 = len(dec_slesnick2008)\n",
    "spt_slesnick2008 = src.organize_spt(slesnick2008_1[1].data['SpT'])\n",
    "ewha_slesnick2008 = slesnick2008_1[1].data['EWHa']*(-1)\n",
    "ewha_err_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "lhalbol_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "lhalbol_err_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "age_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "age_err_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "\n",
    "group_num_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "group_name_slesnick2008 = np.ones(N_slesnick2008)*np.nan\n",
    "source_num_slesnick2008 = np.ones(N_slesnick2008)*source_ref['source_num'][source_ref['source_ref']=='Slesnick 2008'][0]\n",
    "source_ref_slesnick2008 = np.array(['Slesnick 2008' for x in range(N_slesnick2008)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_slesnick2008) \n",
    "dec_all.append(dec_slesnick2008)\n",
    "spt_all.append(spt_slesnick2008)\n",
    "ewha_all.append(ewha_slesnick2008)\n",
    "ewha_err_all.append(ewha_err_slesnick2008)\n",
    "lhalbol_all.append(lhalbol_slesnick2008)\n",
    "lhalbol_err_all.append(lhalbol_err_slesnick2008)\n",
    "age_all.append(age_slesnick2008)\n",
    "age_err_all.append(age_err_slesnick2008)\n",
    "group_num_all.append(group_num_slesnick2008)\n",
    "group_name_all.append(group_name_slesnick2008)\n",
    "source_num_all.append(source_num_slesnick2008)\n",
    "source_ref_all.append(source_ref_slesnick2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "slesnick2008_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2003 = Table.read('Catalogs/Sources/song2003.csv', format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_song2003,dec_song2003 = [],[]\n",
    "for x,y in zip(np.array(song2003['Ra']),np.array(song2003['De'])):\n",
    "    radec = str(x)+' '+str(y)\n",
    "    coord = SkyCoord(radec, unit=(u.hourangle, u.deg))\n",
    "    ra_song2003.append(coord.ra.deg)\n",
    "    dec_song2003.append(coord.dec.deg)\n",
    "ra_song2003 = np.array(ra_song2003)\n",
    "dec_song2003 = np.array(dec_song2003)\n",
    "N_song2003 = len(dec_song2003)\n",
    "spt_song2003 = np.ones(N_song2003)*np.nan\n",
    "ewha_song2003 = np.array(song2003['HaEW'])*(-1)\n",
    "ewha_err_song2003 = np.ones(N_song2003)*np.nan\n",
    "lhalbol_song2003 = np.ones(N_song2003)*np.nan\n",
    "lhalbol_err_song2003 = np.ones(N_song2003)*np.nan\n",
    "\n",
    "age_song2003 = np.ones(N_song2003)*np.nan\n",
    "age_err_song2003 = np.ones(N_song2003)*np.nan\n",
    "group_num_song2003 = np.ones(N_song2003)*np.nan\n",
    "\n",
    "for x in ['BPMG','ETAC','THA','TWA']:\n",
    "    mask1 = song2003['Group'] == x\n",
    "    age_song2003[mask1] = np.ones(len(song2003['Group'][mask1]))*mg_ref['age'][mg_ref['name']==x][0]\n",
    "    age_err_song2003[mask1] = np.ones(len(song2003['Group'][mask1]))*mg_ref['age_error'][mg_ref['name']==x][0]\n",
    "    group_num_song2003[mask1] = np.ones(len(song2003['Group'][mask1]))*mg_ref['group_num'][mg_ref['name']==x][0]\n",
    "    \n",
    "group_name_song2003 = np.array(song2003['Group'])\n",
    "source_num_song2003 = np.ones(N_song2003)*source_ref['source_num'][source_ref['source_ref']=='Song 2003'][0]\n",
    "source_ref_song2003 = np.array(['Song 2003' for x in range(N_song2003)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_song2003) \n",
    "dec_all.append(dec_song2003)\n",
    "spt_all.append(spt_song2003)\n",
    "ewha_all.append(ewha_song2003)\n",
    "ewha_err_all.append(ewha_err_song2003)\n",
    "lhalbol_all.append(lhalbol_song2003)\n",
    "lhalbol_err_all.append(lhalbol_err_song2003)\n",
    "age_all.append(age_song2003)\n",
    "age_err_all.append(age_err_song2003)\n",
    "group_num_all.append(group_num_song2003)\n",
    "group_name_all.append(group_name_song2003)\n",
    "source_num_all.append(source_num_song2003)\n",
    "source_ref_all.append(source_ref_song2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_song2004 = np.array([129.7129167,129.0446667,131.0380833])     \n",
    "dec_song2004 = np.array([-79.2704444,-79.1384167,-78.5626944])\n",
    "N_song2004 = len(dec_song2004)\n",
    "spt_song2004 = np.array([5,5.5,5])\n",
    "ewha_song2004 = np.array([-10.3,-7.6,-57.8])*(-1)\n",
    "ewha_err_song2004 = np.ones(N_song2004)*np.nan\n",
    "lhalbol_song2004 = np.ones(N_song2004)*np.nan\n",
    "lhalbol_err_song2004 = np.ones(N_song2004)*np.nan\n",
    "age_song2004 = np.ones(N_song2004)*mg_ref['age'][mg_ref['name']=='ETAC'][0]\n",
    "age_err_song2004 = np.ones(N_song2004)*mg_ref['age_error'][mg_ref['name']=='ETAC'][0]\n",
    "\n",
    "group_num_song2004 = np.ones(N_song2004)*mg_ref['group_num'][mg_ref['name']=='ETAC'][0]\n",
    "group_name_song2004 = np.array(['ETAC' for i in range(N_song2004)])\n",
    "source_num_song2004 = np.ones(N_song2004)*source_ref['source_num'][source_ref['source_ref']=='Song 2004'][0]\n",
    "source_ref_song2004 = np.array(['Song 2004' for x in range(N_song2004)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_song2004) \n",
    "dec_all.append(dec_song2004)\n",
    "spt_all.append(spt_song2004)\n",
    "ewha_all.append(ewha_song2004)\n",
    "ewha_err_all.append(ewha_err_song2004)\n",
    "lhalbol_all.append(lhalbol_song2004)\n",
    "lhalbol_err_all.append(lhalbol_err_song2004)\n",
    "age_all.append(age_song2004)\n",
    "age_err_all.append(age_err_song2004)\n",
    "group_num_all.append(group_num_song2004)\n",
    "group_name_all.append(group_name_song2004)\n",
    "source_num_all.append(source_num_song2004)\n",
    "source_ref_all.append(source_ref_song2004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stauffer 1997 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terrien 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrien2015 = fits.open('Catalogs/Sources/Terrien2015.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_terrien2015 = terrien2015[1].data['RAJ2000']     \n",
    "dec_terrien2015 = terrien2015[1].data['DEJ2000']\n",
    "N_terrien2015 = len(dec_terrien2015)\n",
    "spt_terrien2015 = terrien2015[1].data['SpT']\n",
    "ewha_terrien2015 = terrien2015[1].data['EWHa']\n",
    "ewha_err_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "lhalbol_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "lhalbol_err_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "age_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "age_err_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "\n",
    "group_num_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "group_name_terrien2015 = np.ones(N_terrien2015)*np.nan\n",
    "source_num_terrien2015 = np.ones(N_terrien2015)*source_ref['source_num'][source_ref['source_ref']=='Terrien 2015'][0]\n",
    "source_ref_terrien2015 = np.array(['Terrien 2015' for x in range(N_terrien2015)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_terrien2015) \n",
    "dec_all.append(dec_terrien2015)\n",
    "spt_all.append(spt_terrien2015)\n",
    "ewha_all.append(ewha_terrien2015)\n",
    "ewha_err_all.append(ewha_err_terrien2015)\n",
    "lhalbol_all.append(lhalbol_terrien2015)\n",
    "lhalbol_err_all.append(lhalbol_err_terrien2015)\n",
    "age_all.append(age_terrien2015)\n",
    "age_err_all.append(age_err_terrien2015)\n",
    "group_num_all.append(group_num_terrien2015)\n",
    "group_name_all.append(group_name_terrien2015)\n",
    "source_num_all.append(source_num_terrien2015)\n",
    "source_ref_all.append(source_ref_terrien2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrien2015.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tinney 1998 (with Newton 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torres 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "torres2006 = fits.open('Catalogs/Sources/Torres2006.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt_mask = []\n",
    "for x in torres2006[1].data['SpType']:\n",
    "    if('M' in x):\n",
    "        spt_mask.append(True)\n",
    "    else:\n",
    "        spt_mask.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_torres2006 = torres2006[1].data['RAJ2000'][spt_mask]     \n",
    "dec_torres2006 = torres2006[1].data['DEJ2000'][spt_mask]\n",
    "N_torres2006 = len(dec_torres2006)\n",
    "spt_torres2006 = src.organize_spt(torres2006[1].data['SpType'][spt_mask])\n",
    "ewha_torres2006 = torres2006[1].data['EWHa'][spt_mask]\n",
    "ewha_err_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "lhalbol_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "lhalbol_err_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "age_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "age_err_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "\n",
    "group_num_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "group_name_torres2006 = np.ones(N_torres2006)*np.nan\n",
    "source_num_torres2006 = np.ones(N_torres2006)*source_ref['source_num'][source_ref['source_ref']=='Torres 2006'][0]\n",
    "source_ref_torres2006 = np.array(['Torres 2006' for x in range(N_torres2006)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_all.append(ra_torres2006) \n",
    "dec_all.append(dec_torres2006)\n",
    "spt_all.append(spt_torres2006)\n",
    "ewha_all.append(ewha_torres2006)\n",
    "ewha_err_all.append(ewha_err_torres2006)\n",
    "lhalbol_all.append(lhalbol_torres2006)\n",
    "lhalbol_err_all.append(lhalbol_err_torres2006)\n",
    "age_all.append(age_torres2006)\n",
    "age_err_all.append(age_err_torres2006)\n",
    "group_num_all.append(group_num_torres2006)\n",
    "group_name_all.append(group_name_torres2006)\n",
    "source_num_all.append(source_num_torres2006)\n",
    "source_ref_all.append(source_ref_torres2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "torres2006.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "literaturesearch = Table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "literaturesearch['ra'] = np.concatenate([ra_i for ra_i in ra_all])\n",
    "literaturesearch['dec'] = np.concatenate([dec_i for dec_i in dec_all])\n",
    "literaturesearch['spt'] = np.concatenate([spt_i for spt_i in spt_all])\n",
    "literaturesearch['ewha'] = np.concatenate([ewha_i for ewha_i in ewha_all])\n",
    "literaturesearch['ewha_error'] = np.concatenate([ewha_err_i for ewha_err_i in ewha_err_all])\n",
    "literaturesearch['lhalbol'] = np.concatenate([lhalbol_i for lhalbol_i in lhalbol_all])\n",
    "literaturesearch['lhalbol_error'] = np.concatenate([lhalbol_err_i for lhalbol_err_i in lhalbol_err_all])\n",
    "literaturesearch['age'] = np.concatenate([age_i for age_i in age_all])\n",
    "literaturesearch['age_error'] = np.concatenate([age_err_i for age_err_i in age_err_all])\n",
    "literaturesearch['group_num'] = np.concatenate([group_num_i for group_num_i in group_num_all])\n",
    "literaturesearch['group_name'] = np.concatenate([group_name_i for group_name_i in group_name_all])\n",
    "literaturesearch['source_num'] = np.concatenate([source_num_i for source_num_i in source_num_all])\n",
    "literaturesearch['source_ref'] = np.concatenate([source_ref_i for source_ref_i in source_ref_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "literaturesearch.sort(['source_ref', 'ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#literaturesearch.write('Catalogs/mactivity_movinggroups.fits',format='fits',overwrite=True)\n",
    "literaturesearch.write('Catalogs/literature_search.fits',format='fits',overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
